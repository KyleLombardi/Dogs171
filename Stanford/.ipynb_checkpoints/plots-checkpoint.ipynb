{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c480d74a-d567-46ac-812c-a790df98caa7",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7599a31-d302-46c6-a558-35b7d3a2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd374a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200cbb76-e40c-4f79-aef7-404b7e0777f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('features.csv')\n",
    "\n",
    "# x = df['Features']\n",
    "# y = df['Breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84336ead-25d3-401b-9e0e-311c35f29391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "LEARN_RATE = 0.01\n",
    "FIRST_LAYER = 128 \n",
    "ACTIVATION_1 = 'relu'\n",
    "SECOND_LAYER = 64\n",
    "ACTIVATION_2 = 'softmax'\n",
    "ACTIVATION_OUT = 'softmax'\n",
    "LOSS_TYPE = 'sparse_categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "EPOCHS = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c12fe28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 90</th>\n",
       "      <th>Feature 91</th>\n",
       "      <th>Feature 92</th>\n",
       "      <th>Feature 93</th>\n",
       "      <th>Feature 94</th>\n",
       "      <th>Feature 95</th>\n",
       "      <th>Feature 96</th>\n",
       "      <th>Feature 97</th>\n",
       "      <th>Feature 98</th>\n",
       "      <th>Feature 99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>-5.279870</td>\n",
       "      <td>-2.208426</td>\n",
       "      <td>5.211814</td>\n",
       "      <td>-8.099501</td>\n",
       "      <td>-13.185220</td>\n",
       "      <td>-0.753768</td>\n",
       "      <td>-3.015471</td>\n",
       "      <td>0.825370</td>\n",
       "      <td>-4.269372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465695</td>\n",
       "      <td>-0.674558</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>-1.240681</td>\n",
       "      <td>-1.069499</td>\n",
       "      <td>-0.714136</td>\n",
       "      <td>1.011624</td>\n",
       "      <td>-0.225715</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>1.140998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>0.524020</td>\n",
       "      <td>-4.321692</td>\n",
       "      <td>-5.808849</td>\n",
       "      <td>-0.097443</td>\n",
       "      <td>-13.157566</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>-4.521323</td>\n",
       "      <td>-1.382092</td>\n",
       "      <td>-1.304059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410429</td>\n",
       "      <td>0.396908</td>\n",
       "      <td>0.344853</td>\n",
       "      <td>0.243527</td>\n",
       "      <td>-0.416206</td>\n",
       "      <td>0.310021</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>-0.221647</td>\n",
       "      <td>-0.306602</td>\n",
       "      <td>-0.855617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>4.484349</td>\n",
       "      <td>-11.409184</td>\n",
       "      <td>-2.061785</td>\n",
       "      <td>-8.795961</td>\n",
       "      <td>-10.736951</td>\n",
       "      <td>-0.650287</td>\n",
       "      <td>0.697348</td>\n",
       "      <td>8.464226</td>\n",
       "      <td>-2.961214</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.486026</td>\n",
       "      <td>0.636264</td>\n",
       "      <td>-0.315544</td>\n",
       "      <td>1.400241</td>\n",
       "      <td>-0.116869</td>\n",
       "      <td>-0.253275</td>\n",
       "      <td>0.918089</td>\n",
       "      <td>-0.645903</td>\n",
       "      <td>0.545067</td>\n",
       "      <td>-1.274210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>8.630311</td>\n",
       "      <td>-9.028896</td>\n",
       "      <td>-4.177602</td>\n",
       "      <td>-3.575223</td>\n",
       "      <td>-7.698362</td>\n",
       "      <td>-5.857273</td>\n",
       "      <td>-3.473359</td>\n",
       "      <td>6.915802</td>\n",
       "      <td>1.972978</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.718268</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.152345</td>\n",
       "      <td>0.562226</td>\n",
       "      <td>0.279578</td>\n",
       "      <td>-0.277104</td>\n",
       "      <td>-0.956852</td>\n",
       "      <td>-0.531012</td>\n",
       "      <td>0.249064</td>\n",
       "      <td>-1.877944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>-6.459163</td>\n",
       "      <td>-5.178344</td>\n",
       "      <td>3.182314</td>\n",
       "      <td>-6.884826</td>\n",
       "      <td>-2.663270</td>\n",
       "      <td>-0.779802</td>\n",
       "      <td>-0.788943</td>\n",
       "      <td>4.521932</td>\n",
       "      <td>-3.636744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.964177</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>-0.274313</td>\n",
       "      <td>-0.534803</td>\n",
       "      <td>0.797063</td>\n",
       "      <td>-0.156896</td>\n",
       "      <td>1.027882</td>\n",
       "      <td>1.130965</td>\n",
       "      <td>0.696718</td>\n",
       "      <td>0.098893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20423</th>\n",
       "      <td>basenji</td>\n",
       "      <td>9.544751</td>\n",
       "      <td>-11.946300</td>\n",
       "      <td>6.532518</td>\n",
       "      <td>6.032665</td>\n",
       "      <td>-0.054745</td>\n",
       "      <td>-2.835599</td>\n",
       "      <td>8.757513</td>\n",
       "      <td>2.183208</td>\n",
       "      <td>-3.308503</td>\n",
       "      <td>...</td>\n",
       "      <td>2.823255</td>\n",
       "      <td>1.785358</td>\n",
       "      <td>-0.389777</td>\n",
       "      <td>2.354301</td>\n",
       "      <td>-0.200981</td>\n",
       "      <td>1.370857</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.747879</td>\n",
       "      <td>-1.344105</td>\n",
       "      <td>-1.186251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20424</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-14.772338</td>\n",
       "      <td>-8.129835</td>\n",
       "      <td>6.266210</td>\n",
       "      <td>9.255338</td>\n",
       "      <td>-0.755042</td>\n",
       "      <td>-10.281703</td>\n",
       "      <td>-4.626710</td>\n",
       "      <td>3.558872</td>\n",
       "      <td>-6.597734</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.323281</td>\n",
       "      <td>-0.496995</td>\n",
       "      <td>-1.813071</td>\n",
       "      <td>0.129572</td>\n",
       "      <td>-0.680327</td>\n",
       "      <td>0.759279</td>\n",
       "      <td>-0.898638</td>\n",
       "      <td>0.825506</td>\n",
       "      <td>-1.794241</td>\n",
       "      <td>0.535946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20425</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-0.651727</td>\n",
       "      <td>-14.567093</td>\n",
       "      <td>19.406995</td>\n",
       "      <td>0.646407</td>\n",
       "      <td>10.396984</td>\n",
       "      <td>-6.700563</td>\n",
       "      <td>-4.514317</td>\n",
       "      <td>13.566748</td>\n",
       "      <td>-2.614418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.489337</td>\n",
       "      <td>2.132769</td>\n",
       "      <td>0.234950</td>\n",
       "      <td>-1.367633</td>\n",
       "      <td>-1.451568</td>\n",
       "      <td>0.228860</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>0.696946</td>\n",
       "      <td>-0.543697</td>\n",
       "      <td>-1.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20426</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-1.703676</td>\n",
       "      <td>-2.682114</td>\n",
       "      <td>14.418438</td>\n",
       "      <td>7.169161</td>\n",
       "      <td>6.828974</td>\n",
       "      <td>-6.077620</td>\n",
       "      <td>-2.837851</td>\n",
       "      <td>11.472995</td>\n",
       "      <td>-8.041656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.308288</td>\n",
       "      <td>-0.401849</td>\n",
       "      <td>1.429980</td>\n",
       "      <td>-0.723179</td>\n",
       "      <td>-2.111574</td>\n",
       "      <td>-1.035175</td>\n",
       "      <td>-0.324995</td>\n",
       "      <td>0.698054</td>\n",
       "      <td>0.101706</td>\n",
       "      <td>0.878638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20427</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-1.798135</td>\n",
       "      <td>-4.808407</td>\n",
       "      <td>4.453213</td>\n",
       "      <td>6.871646</td>\n",
       "      <td>2.610319</td>\n",
       "      <td>-11.454654</td>\n",
       "      <td>3.632534</td>\n",
       "      <td>-3.067008</td>\n",
       "      <td>-3.319274</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.445148</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.543326</td>\n",
       "      <td>-0.379736</td>\n",
       "      <td>-1.181225</td>\n",
       "      <td>1.674236</td>\n",
       "      <td>0.643497</td>\n",
       "      <td>1.456580</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>1.196227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20428 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Breed  Feature 0  Feature 1  Feature 2  Feature 3  \\\n",
       "0      brittany_spaniel  -5.279870  -2.208426   5.211814  -8.099501   \n",
       "1      brittany_spaniel   0.524020  -4.321692  -5.808849  -0.097443   \n",
       "2      brittany_spaniel   4.484349 -11.409184  -2.061785  -8.795961   \n",
       "3      brittany_spaniel   8.630311  -9.028896  -4.177602  -3.575223   \n",
       "4      brittany_spaniel  -6.459163  -5.178344   3.182314  -6.884826   \n",
       "...                 ...        ...        ...        ...        ...   \n",
       "20423           basenji   9.544751 -11.946300   6.532518   6.032665   \n",
       "20424           basenji -14.772338  -8.129835   6.266210   9.255338   \n",
       "20425           basenji  -0.651727 -14.567093  19.406995   0.646407   \n",
       "20426           basenji  -1.703676  -2.682114  14.418438   7.169161   \n",
       "20427           basenji  -1.798135  -4.808407   4.453213   6.871646   \n",
       "\n",
       "       Feature 4  Feature 5  Feature 6  Feature 7  Feature 8  ...  Feature 90  \\\n",
       "0     -13.185220  -0.753768  -3.015471   0.825370  -4.269372  ...   -0.465695   \n",
       "1     -13.157566   0.439865  -4.521323  -1.382092  -1.304059  ...   -0.410429   \n",
       "2     -10.736951  -0.650287   0.697348   8.464226  -2.961214  ...   -1.486026   \n",
       "3      -7.698362  -5.857273  -3.473359   6.915802   1.972978  ...   -1.718268   \n",
       "4      -2.663270  -0.779802  -0.788943   4.521932  -3.636744  ...   -0.964177   \n",
       "...          ...        ...        ...        ...        ...  ...         ...   \n",
       "20423  -0.054745  -2.835599   8.757513   2.183208  -3.308503  ...    2.823255   \n",
       "20424  -0.755042 -10.281703  -4.626710   3.558872  -6.597734  ...   -1.323281   \n",
       "20425  10.396984  -6.700563  -4.514317  13.566748  -2.614418  ...   -0.489337   \n",
       "20426   6.828974  -6.077620  -2.837851  11.472995  -8.041656  ...    1.308288   \n",
       "20427   2.610319 -11.454654   3.632534  -3.067008  -3.319274  ...   -1.445148   \n",
       "\n",
       "       Feature 91  Feature 92  Feature 93  Feature 94  Feature 95  Feature 96  \\\n",
       "0       -0.674558    0.123558   -1.240681   -1.069499   -0.714136    1.011624   \n",
       "1        0.396908    0.344853    0.243527   -0.416206    0.310021    0.025371   \n",
       "2        0.636264   -0.315544    1.400241   -0.116869   -0.253275    0.918089   \n",
       "3        0.056995    0.152345    0.562226    0.279578   -0.277104   -0.956852   \n",
       "4        0.368517   -0.274313   -0.534803    0.797063   -0.156896    1.027882   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "20423    1.785358   -0.389777    2.354301   -0.200981    1.370857    0.069524   \n",
       "20424   -0.496995   -1.813071    0.129572   -0.680327    0.759279   -0.898638   \n",
       "20425    2.132769    0.234950   -1.367633   -1.451568    0.228860   -0.094061   \n",
       "20426   -0.401849    1.429980   -0.723179   -2.111574   -1.035175   -0.324995   \n",
       "20427    0.125831    0.543326   -0.379736   -1.181225    1.674236    0.643497   \n",
       "\n",
       "       Feature 97  Feature 98  Feature 99  \n",
       "0       -0.225715   -0.220330    1.140998  \n",
       "1       -0.221647   -0.306602   -0.855617  \n",
       "2       -0.645903    0.545067   -1.274210  \n",
       "3       -0.531012    0.249064   -1.877944  \n",
       "4        1.130965    0.696718    0.098893  \n",
       "...           ...         ...         ...  \n",
       "20423    0.747879   -1.344105   -1.186251  \n",
       "20424    0.825506   -1.794241    0.535946  \n",
       "20425    0.696946   -0.543697   -1.004654  \n",
       "20426    0.698054    0.101706    0.878638  \n",
       "20427    1.456580   -0.038680    1.196227  \n",
       "\n",
       "[20428 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f989db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breed\n",
       "maltese_dog             40\n",
       "afghan_hound            38\n",
       "scottish_deerhound      38\n",
       "pomeranian              37\n",
       "bernese_mountain_dog    37\n",
       "Name: count, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 90</th>\n",
       "      <th>Feature 91</th>\n",
       "      <th>Feature 92</th>\n",
       "      <th>Feature 93</th>\n",
       "      <th>Feature 94</th>\n",
       "      <th>Feature 95</th>\n",
       "      <th>Feature 96</th>\n",
       "      <th>Feature 97</th>\n",
       "      <th>Feature 98</th>\n",
       "      <th>Feature 99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-20.371095</td>\n",
       "      <td>2.745416</td>\n",
       "      <td>-15.309989</td>\n",
       "      <td>-11.286719</td>\n",
       "      <td>-6.187973</td>\n",
       "      <td>-5.292492</td>\n",
       "      <td>2.575061</td>\n",
       "      <td>-4.683992</td>\n",
       "      <td>5.752259</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.617760</td>\n",
       "      <td>0.061003</td>\n",
       "      <td>-0.301516</td>\n",
       "      <td>-1.302157</td>\n",
       "      <td>-0.171717</td>\n",
       "      <td>0.235900</td>\n",
       "      <td>-0.031043</td>\n",
       "      <td>-0.755568</td>\n",
       "      <td>-0.639516</td>\n",
       "      <td>0.064571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-17.690462</td>\n",
       "      <td>8.869982</td>\n",
       "      <td>3.605649</td>\n",
       "      <td>-8.214523</td>\n",
       "      <td>4.089065</td>\n",
       "      <td>-5.200577</td>\n",
       "      <td>-2.518791</td>\n",
       "      <td>-6.852842</td>\n",
       "      <td>4.239432</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.061841</td>\n",
       "      <td>1.439840</td>\n",
       "      <td>-0.807200</td>\n",
       "      <td>0.277041</td>\n",
       "      <td>0.271422</td>\n",
       "      <td>-1.085912</td>\n",
       "      <td>0.497780</td>\n",
       "      <td>0.232938</td>\n",
       "      <td>-2.340493</td>\n",
       "      <td>-1.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-20.071307</td>\n",
       "      <td>4.439615</td>\n",
       "      <td>-11.426466</td>\n",
       "      <td>-5.686900</td>\n",
       "      <td>-3.978728</td>\n",
       "      <td>-6.345679</td>\n",
       "      <td>-3.323854</td>\n",
       "      <td>-7.555827</td>\n",
       "      <td>3.248526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.281183</td>\n",
       "      <td>-0.173762</td>\n",
       "      <td>-0.576338</td>\n",
       "      <td>-0.744454</td>\n",
       "      <td>0.676036</td>\n",
       "      <td>-1.443646</td>\n",
       "      <td>1.275629</td>\n",
       "      <td>0.089344</td>\n",
       "      <td>0.776405</td>\n",
       "      <td>0.519873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-24.856036</td>\n",
       "      <td>2.609085</td>\n",
       "      <td>-3.817598</td>\n",
       "      <td>-12.645497</td>\n",
       "      <td>-4.291781</td>\n",
       "      <td>-4.967999</td>\n",
       "      <td>4.998550</td>\n",
       "      <td>-4.562568</td>\n",
       "      <td>2.389172</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.305962</td>\n",
       "      <td>-0.290309</td>\n",
       "      <td>-0.934695</td>\n",
       "      <td>-0.211845</td>\n",
       "      <td>-1.007157</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>0.775138</td>\n",
       "      <td>1.312471</td>\n",
       "      <td>0.301436</td>\n",
       "      <td>-0.319305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-16.587807</td>\n",
       "      <td>5.495782</td>\n",
       "      <td>-7.549476</td>\n",
       "      <td>-7.897998</td>\n",
       "      <td>-0.207670</td>\n",
       "      <td>-5.044512</td>\n",
       "      <td>-1.471277</td>\n",
       "      <td>-5.200042</td>\n",
       "      <td>2.888019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162715</td>\n",
       "      <td>0.274873</td>\n",
       "      <td>-0.303604</td>\n",
       "      <td>0.213484</td>\n",
       "      <td>-0.125910</td>\n",
       "      <td>-0.723596</td>\n",
       "      <td>0.171682</td>\n",
       "      <td>0.899438</td>\n",
       "      <td>-0.252863</td>\n",
       "      <td>-0.247180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Breed  Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0  maltese_dog -20.371095   2.745416 -15.309989 -11.286719  -6.187973   \n",
       "1  maltese_dog -17.690462   8.869982   3.605649  -8.214523   4.089065   \n",
       "2  maltese_dog -20.071307   4.439615 -11.426466  -5.686900  -3.978728   \n",
       "3  maltese_dog -24.856036   2.609085  -3.817598 -12.645497  -4.291781   \n",
       "4  maltese_dog -16.587807   5.495782  -7.549476  -7.897998  -0.207670   \n",
       "\n",
       "   Feature 5  Feature 6  Feature 7  Feature 8  ...  Feature 90  Feature 91  \\\n",
       "0  -5.292492   2.575061  -4.683992   5.752259  ...   -2.617760    0.061003   \n",
       "1  -5.200577  -2.518791  -6.852842   4.239432  ...   -1.061841    1.439840   \n",
       "2  -6.345679  -3.323854  -7.555827   3.248526  ...   -1.281183   -0.173762   \n",
       "3  -4.967999   4.998550  -4.562568   2.389172  ...   -1.305962   -0.290309   \n",
       "4  -5.044512  -1.471277  -5.200042   2.888019  ...   -0.162715    0.274873   \n",
       "\n",
       "   Feature 92  Feature 93  Feature 94  Feature 95  Feature 96  Feature 97  \\\n",
       "0   -0.301516   -1.302157   -0.171717    0.235900   -0.031043   -0.755568   \n",
       "1   -0.807200    0.277041    0.271422   -1.085912    0.497780    0.232938   \n",
       "2   -0.576338   -0.744454    0.676036   -1.443646    1.275629    0.089344   \n",
       "3   -0.934695   -0.211845   -1.007157    0.118234    0.775138    1.312471   \n",
       "4   -0.303604    0.213484   -0.125910   -0.723596    0.171682    0.899438   \n",
       "\n",
       "   Feature 98  Feature 99  \n",
       "0   -0.639516    0.064571  \n",
       "1   -2.340493   -1.016629  \n",
       "2    0.776405    0.519873  \n",
       "3    0.301436   -0.319305  \n",
       "4   -0.252863   -0.247180  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the number of samples to take for each breed\n",
    "breed_counts = df['Breed'].value_counts()\n",
    "max_count = breed_counts.max()\n",
    "sample_sizes = np.maximum(20, 20 + (breed_counts / max_count * 20).astype(int))\n",
    "\n",
    "# Create an empty list to store sampled dataframes\n",
    "sampled_dfs = []\n",
    "\n",
    "# Iterate over each breed to sample data\n",
    "for breed, sample_size in sample_sizes.items():\n",
    "    # Get indices of rows corresponding to the current breed\n",
    "    breed_indices = df[df['Breed'] == breed].index\n",
    "    \n",
    "    # Randomly sample rows for the current breed\n",
    "    sampled_indices = np.random.choice(breed_indices, size=sample_size, replace=False)\n",
    "    \n",
    "    # Append sampled rows to the list\n",
    "    sampled_dfs.append(df.loc[sampled_indices])\n",
    "\n",
    "# Concatenate all sampled dataframes into one\n",
    "sampled_df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "display(sample_sizes.head())\n",
    "display(sampled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20e9f19a-4a2a-496b-b444-21cc53a0b516",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m sampled_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m sampled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(x, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      8\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate some dummy data for training\n",
    "\n",
    "x = sampled_df.drop(columns=['Breed'])\n",
    "\n",
    "y = sampled_df['Breed']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "num_classes = 120\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b11822a6-d107-4ba2-b268-e31efe07dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 1s 6ms/step - loss: 4.7869 - accuracy: 0.0088 - val_loss: 4.7884 - val_accuracy: 0.0100\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7808 - accuracy: 0.0125 - val_loss: 4.7882 - val_accuracy: 0.0050\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7756 - accuracy: 0.0125 - val_loss: 4.7899 - val_accuracy: 0.0050\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7697 - accuracy: 0.0113 - val_loss: 4.7905 - val_accuracy: 0.0100\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7639 - accuracy: 0.0175 - val_loss: 4.7934 - val_accuracy: 0.0150\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7594 - accuracy: 0.0150 - val_loss: 4.7950 - val_accuracy: 0.0150\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7535 - accuracy: 0.0188 - val_loss: 4.7971 - val_accuracy: 0.0100\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7497 - accuracy: 0.0200 - val_loss: 4.7965 - val_accuracy: 0.0150\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7449 - accuracy: 0.0200 - val_loss: 4.7971 - val_accuracy: 0.0150\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7393 - accuracy: 0.0188 - val_loss: 4.8007 - val_accuracy: 0.0100\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7338 - accuracy: 0.0250 - val_loss: 4.8005 - val_accuracy: 0.0150\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7297 - accuracy: 0.0200 - val_loss: 4.8022 - val_accuracy: 0.0100\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7256 - accuracy: 0.0225 - val_loss: 4.8038 - val_accuracy: 0.0100\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7186 - accuracy: 0.0237 - val_loss: 4.8053 - val_accuracy: 0.0100\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7155 - accuracy: 0.0250 - val_loss: 4.8080 - val_accuracy: 0.0100\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7093 - accuracy: 0.0188 - val_loss: 4.8088 - val_accuracy: 0.0100\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7034 - accuracy: 0.0225 - val_loss: 4.8093 - val_accuracy: 0.0100\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.6985 - accuracy: 0.0237 - val_loss: 4.8123 - val_accuracy: 0.0100\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6938 - accuracy: 0.0225 - val_loss: 4.8124 - val_accuracy: 0.0100\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6878 - accuracy: 0.0237 - val_loss: 4.8116 - val_accuracy: 0.0100\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6822 - accuracy: 0.0262 - val_loss: 4.8131 - val_accuracy: 0.0100\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6770 - accuracy: 0.0288 - val_loss: 4.8146 - val_accuracy: 0.0100\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6693 - accuracy: 0.0312 - val_loss: 4.8160 - val_accuracy: 0.0100\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6652 - accuracy: 0.0275 - val_loss: 4.8174 - val_accuracy: 0.0100\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6598 - accuracy: 0.0288 - val_loss: 4.8187 - val_accuracy: 0.0050\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6549 - accuracy: 0.0312 - val_loss: 4.8198 - val_accuracy: 0.0050\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6468 - accuracy: 0.0300 - val_loss: 4.8214 - val_accuracy: 0.0050\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6406 - accuracy: 0.0300 - val_loss: 4.8233 - val_accuracy: 0.0050\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6350 - accuracy: 0.0325 - val_loss: 4.8228 - val_accuracy: 0.0100\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.6281 - accuracy: 0.0288 - val_loss: 4.8249 - val_accuracy: 0.0050\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6222 - accuracy: 0.0300 - val_loss: 4.8270 - val_accuracy: 0.0050\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6164 - accuracy: 0.0325 - val_loss: 4.8275 - val_accuracy: 0.0050\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6084 - accuracy: 0.0350 - val_loss: 4.8302 - val_accuracy: 0.0050\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.6026 - accuracy: 0.0375 - val_loss: 4.8303 - val_accuracy: 0.0050\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5958 - accuracy: 0.0375 - val_loss: 4.8328 - val_accuracy: 0.0050\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4.5921 - accuracy: 0.0388 - val_loss: 4.8334 - val_accuracy: 0.0050\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5843 - accuracy: 0.0413 - val_loss: 4.8383 - val_accuracy: 0.0050\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5781 - accuracy: 0.0388 - val_loss: 4.8368 - val_accuracy: 0.0050\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5715 - accuracy: 0.0400 - val_loss: 4.8370 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5656 - accuracy: 0.0413 - val_loss: 4.8390 - val_accuracy: 0.0050\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5581 - accuracy: 0.0400 - val_loss: 4.8397 - val_accuracy: 0.0050\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5518 - accuracy: 0.0388 - val_loss: 4.8433 - val_accuracy: 0.0050\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5462 - accuracy: 0.0350 - val_loss: 4.8419 - val_accuracy: 0.0050\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5407 - accuracy: 0.0375 - val_loss: 4.8425 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5327 - accuracy: 0.0388 - val_loss: 4.8452 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5283 - accuracy: 0.0350 - val_loss: 4.8472 - val_accuracy: 0.0050\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5202 - accuracy: 0.0413 - val_loss: 4.8485 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5159 - accuracy: 0.0388 - val_loss: 4.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5095 - accuracy: 0.0375 - val_loss: 4.8545 - val_accuracy: 0.0050\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5043 - accuracy: 0.0388 - val_loss: 4.8562 - val_accuracy: 0.0050\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4984 - accuracy: 0.0437 - val_loss: 4.8569 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4935 - accuracy: 0.0425 - val_loss: 4.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4868 - accuracy: 0.0413 - val_loss: 4.8591 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4794 - accuracy: 0.0425 - val_loss: 4.8605 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4727 - accuracy: 0.0437 - val_loss: 4.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4693 - accuracy: 0.0450 - val_loss: 4.8632 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4597 - accuracy: 0.0463 - val_loss: 4.8651 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4545 - accuracy: 0.0500 - val_loss: 4.8671 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4492 - accuracy: 0.0450 - val_loss: 4.8702 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4426 - accuracy: 0.0425 - val_loss: 4.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4364 - accuracy: 0.0450 - val_loss: 4.8726 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4289 - accuracy: 0.0487 - val_loss: 4.8720 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4237 - accuracy: 0.0475 - val_loss: 4.8800 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4178 - accuracy: 0.0475 - val_loss: 4.8752 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4146 - accuracy: 0.0425 - val_loss: 4.8769 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4115 - accuracy: 0.0413 - val_loss: 4.8822 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4019 - accuracy: 0.0437 - val_loss: 4.8854 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3979 - accuracy: 0.0437 - val_loss: 4.8932 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3922 - accuracy: 0.0425 - val_loss: 4.8863 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3845 - accuracy: 0.0437 - val_loss: 4.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3788 - accuracy: 0.0437 - val_loss: 4.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3743 - accuracy: 0.0437 - val_loss: 4.9027 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3677 - accuracy: 0.0425 - val_loss: 4.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3615 - accuracy: 0.0388 - val_loss: 4.9020 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3570 - accuracy: 0.0413 - val_loss: 4.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3513 - accuracy: 0.0425 - val_loss: 4.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3479 - accuracy: 0.0425 - val_loss: 4.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3434 - accuracy: 0.0437 - val_loss: 4.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3353 - accuracy: 0.0400 - val_loss: 4.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3299 - accuracy: 0.0437 - val_loss: 4.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3257 - accuracy: 0.0375 - val_loss: 4.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3205 - accuracy: 0.0413 - val_loss: 4.9273 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3152 - accuracy: 0.0400 - val_loss: 4.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3108 - accuracy: 0.0450 - val_loss: 4.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3037 - accuracy: 0.0437 - val_loss: 4.9381 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2979 - accuracy: 0.0413 - val_loss: 4.9372 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2934 - accuracy: 0.0437 - val_loss: 4.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2881 - accuracy: 0.0413 - val_loss: 4.9456 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2828 - accuracy: 0.0463 - val_loss: 4.9488 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2778 - accuracy: 0.0388 - val_loss: 4.9540 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2723 - accuracy: 0.0413 - val_loss: 4.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2679 - accuracy: 0.0400 - val_loss: 4.9559 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2631 - accuracy: 0.0450 - val_loss: 4.9592 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2597 - accuracy: 0.0400 - val_loss: 4.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2545 - accuracy: 0.0437 - val_loss: 4.9689 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2497 - accuracy: 0.0388 - val_loss: 4.9718 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2450 - accuracy: 0.0425 - val_loss: 4.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2428 - accuracy: 0.0437 - val_loss: 4.9819 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2386 - accuracy: 0.0437 - val_loss: 4.9747 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2356 - accuracy: 0.0425 - val_loss: 4.9820 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2304 - accuracy: 0.0437 - val_loss: 4.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2256 - accuracy: 0.0425 - val_loss: 4.9871 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2209 - accuracy: 0.0437 - val_loss: 4.9916 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2172 - accuracy: 0.0400 - val_loss: 4.9956 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2124 - accuracy: 0.0425 - val_loss: 4.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2077 - accuracy: 0.0425 - val_loss: 5.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2036 - accuracy: 0.0437 - val_loss: 5.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1989 - accuracy: 0.0388 - val_loss: 5.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.1960 - accuracy: 0.0437 - val_loss: 5.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1915 - accuracy: 0.0425 - val_loss: 5.0240 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1868 - accuracy: 0.0425 - val_loss: 5.0233 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1829 - accuracy: 0.0425 - val_loss: 5.0218 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1796 - accuracy: 0.0425 - val_loss: 5.0260 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1756 - accuracy: 0.0437 - val_loss: 5.0296 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1716 - accuracy: 0.0425 - val_loss: 5.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1686 - accuracy: 0.0437 - val_loss: 5.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1649 - accuracy: 0.0425 - val_loss: 5.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1615 - accuracy: 0.0425 - val_loss: 5.0500 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1586 - accuracy: 0.0425 - val_loss: 5.0526 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1551 - accuracy: 0.0425 - val_loss: 5.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1521 - accuracy: 0.0425 - val_loss: 5.0609 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1494 - accuracy: 0.0425 - val_loss: 5.0593 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1463 - accuracy: 0.0450 - val_loss: 5.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1426 - accuracy: 0.0450 - val_loss: 5.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1392 - accuracy: 0.0437 - val_loss: 5.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1375 - accuracy: 0.0437 - val_loss: 5.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1348 - accuracy: 0.0463 - val_loss: 5.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1330 - accuracy: 0.0437 - val_loss: 5.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1292 - accuracy: 0.0463 - val_loss: 5.0793 - val_accuracy: 0.0050\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1254 - accuracy: 0.0463 - val_loss: 5.0822 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1217 - accuracy: 0.0437 - val_loss: 5.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1182 - accuracy: 0.0425 - val_loss: 5.1001 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1174 - accuracy: 0.0475 - val_loss: 5.0906 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1142 - accuracy: 0.0437 - val_loss: 5.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1104 - accuracy: 0.0487 - val_loss: 5.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1078 - accuracy: 0.0450 - val_loss: 5.1210 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1057 - accuracy: 0.0500 - val_loss: 5.1138 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1022 - accuracy: 0.0487 - val_loss: 5.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1046 - accuracy: 0.0463 - val_loss: 5.1252 - val_accuracy: 0.0050\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1061 - accuracy: 0.0475 - val_loss: 5.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0957 - accuracy: 0.0512 - val_loss: 5.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0905 - accuracy: 0.0463 - val_loss: 5.1268 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0869 - accuracy: 0.0475 - val_loss: 5.1369 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0833 - accuracy: 0.0463 - val_loss: 5.1342 - val_accuracy: 0.0050\n",
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0810 - accuracy: 0.0437 - val_loss: 5.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0795 - accuracy: 0.0500 - val_loss: 5.1635 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0783 - accuracy: 0.0500 - val_loss: 5.1384 - val_accuracy: 0.0050\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0779 - accuracy: 0.0512 - val_loss: 5.1860 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0724 - accuracy: 0.0525 - val_loss: 5.1693 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0686 - accuracy: 0.0538 - val_loss: 5.1750 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0666 - accuracy: 0.0487 - val_loss: 5.1802 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0648 - accuracy: 0.0463 - val_loss: 5.1962 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0624 - accuracy: 0.0450 - val_loss: 5.1959 - val_accuracy: 0.0050\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0617 - accuracy: 0.0463 - val_loss: 5.2169 - val_accuracy: 0.0050\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0597 - accuracy: 0.0463 - val_loss: 5.1717 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0635 - accuracy: 0.0475 - val_loss: 5.1775 - val_accuracy: 0.0050\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0548 - accuracy: 0.0450 - val_loss: 5.2160 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0521 - accuracy: 0.0487 - val_loss: 5.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0486 - accuracy: 0.0437 - val_loss: 5.2071 - val_accuracy: 0.0050\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0467 - accuracy: 0.0475 - val_loss: 5.2148 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0476 - accuracy: 0.0463 - val_loss: 5.2086 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0463 - accuracy: 0.0475 - val_loss: 5.1970 - val_accuracy: 0.0050\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0398 - accuracy: 0.0487 - val_loss: 5.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0356 - accuracy: 0.0463 - val_loss: 5.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.0314 - accuracy: 0.0525 - val_loss: 5.2356 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0274 - accuracy: 0.0487 - val_loss: 5.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0260 - accuracy: 0.0512 - val_loss: 5.2486 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0231 - accuracy: 0.0487 - val_loss: 5.2580 - val_accuracy: 0.0050\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0220 - accuracy: 0.0500 - val_loss: 5.2513 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0180 - accuracy: 0.0512 - val_loss: 5.2493 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0190 - accuracy: 0.0500 - val_loss: 5.2503 - val_accuracy: 0.0050\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0184 - accuracy: 0.0475 - val_loss: 5.2911 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0167 - accuracy: 0.0500 - val_loss: 5.2773 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0129 - accuracy: 0.0500 - val_loss: 5.2937 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0122 - accuracy: 0.0487 - val_loss: 5.2748 - val_accuracy: 0.0050\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0119 - accuracy: 0.0512 - val_loss: 5.2692 - val_accuracy: 0.0050\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0092 - accuracy: 0.0487 - val_loss: 5.2797 - val_accuracy: 0.0050\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0036 - accuracy: 0.0463 - val_loss: 5.2933 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0005 - accuracy: 0.0500 - val_loss: 5.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9987 - accuracy: 0.0500 - val_loss: 5.3042 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9987 - accuracy: 0.0525 - val_loss: 5.2795 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9978 - accuracy: 0.0525 - val_loss: 5.2826 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9980 - accuracy: 0.0475 - val_loss: 5.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9927 - accuracy: 0.0525 - val_loss: 5.3050 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9859 - accuracy: 0.0500 - val_loss: 5.3256 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9811 - accuracy: 0.0512 - val_loss: 5.3234 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9764 - accuracy: 0.0525 - val_loss: 5.3207 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9757 - accuracy: 0.0575 - val_loss: 5.3214 - val_accuracy: 0.0050\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9719 - accuracy: 0.0538 - val_loss: 5.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9695 - accuracy: 0.0562 - val_loss: 5.3292 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9676 - accuracy: 0.0512 - val_loss: 5.3317 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9676 - accuracy: 0.0550 - val_loss: 5.3527 - val_accuracy: 0.0050\n",
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9678 - accuracy: 0.0575 - val_loss: 5.3347 - val_accuracy: 0.0050\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9625 - accuracy: 0.0587 - val_loss: 5.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9598 - accuracy: 0.0575 - val_loss: 5.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9602 - accuracy: 0.0562 - val_loss: 5.3685 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9605 - accuracy: 0.0550 - val_loss: 5.3499 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9562 - accuracy: 0.0550 - val_loss: 5.3629 - val_accuracy: 0.0050\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9534 - accuracy: 0.0550 - val_loss: 5.3551 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9538 - accuracy: 0.0587 - val_loss: 5.3764 - val_accuracy: 0.0050\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9495 - accuracy: 0.0625 - val_loss: 5.3856 - val_accuracy: 0.0050\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.9464 - accuracy: 0.0600 - val_loss: 5.3971 - val_accuracy: 0.0050\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9456 - accuracy: 0.0600 - val_loss: 5.3762 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9489 - accuracy: 0.0525 - val_loss: 5.3738 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9509 - accuracy: 0.0538 - val_loss: 5.4079 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9464 - accuracy: 0.0538 - val_loss: 5.3888 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9441 - accuracy: 0.0550 - val_loss: 5.3866 - val_accuracy: 0.0050\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9395 - accuracy: 0.0538 - val_loss: 5.4083 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9361 - accuracy: 0.0587 - val_loss: 5.4303 - val_accuracy: 0.0050\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9407 - accuracy: 0.0562 - val_loss: 5.4051 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9323 - accuracy: 0.0538 - val_loss: 5.4176 - val_accuracy: 0.0050\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.9277 - accuracy: 0.0587 - val_loss: 5.4156 - val_accuracy: 0.0050\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9303 - accuracy: 0.0575 - val_loss: 5.4185 - val_accuracy: 0.0050\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9264 - accuracy: 0.0562 - val_loss: 5.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9221 - accuracy: 0.0575 - val_loss: 5.4411 - val_accuracy: 0.0050\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9202 - accuracy: 0.0562 - val_loss: 5.4515 - val_accuracy: 0.0050\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9195 - accuracy: 0.0613 - val_loss: 5.4318 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9166 - accuracy: 0.0600 - val_loss: 5.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9149 - accuracy: 0.0575 - val_loss: 5.4492 - val_accuracy: 0.0050\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9151 - accuracy: 0.0600 - val_loss: 5.4570 - val_accuracy: 0.0050\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9161 - accuracy: 0.0587 - val_loss: 5.4468 - val_accuracy: 0.0050\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9205 - accuracy: 0.0625 - val_loss: 5.4435 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9124 - accuracy: 0.0575 - val_loss: 5.4557 - val_accuracy: 0.0050\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9072 - accuracy: 0.0587 - val_loss: 5.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9061 - accuracy: 0.0613 - val_loss: 5.4972 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9019 - accuracy: 0.0575 - val_loss: 5.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8963 - accuracy: 0.0625 - val_loss: 5.4829 - val_accuracy: 0.0050\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8956 - accuracy: 0.0600 - val_loss: 5.4840 - val_accuracy: 0.0050\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8949 - accuracy: 0.0662 - val_loss: 5.4805 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8938 - accuracy: 0.0625 - val_loss: 5.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8917 - accuracy: 0.0662 - val_loss: 5.5033 - val_accuracy: 0.0050\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8919 - accuracy: 0.0613 - val_loss: 5.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8936 - accuracy: 0.0625 - val_loss: 5.4958 - val_accuracy: 0.0050\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8901 - accuracy: 0.0587 - val_loss: 5.5387 - val_accuracy: 0.0050\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8903 - accuracy: 0.0613 - val_loss: 5.5136 - val_accuracy: 0.0050\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8855 - accuracy: 0.0688 - val_loss: 5.5201 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8823 - accuracy: 0.0637 - val_loss: 5.5067 - val_accuracy: 0.0050\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8793 - accuracy: 0.0662 - val_loss: 5.5172 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8750 - accuracy: 0.0675 - val_loss: 5.5358 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8720 - accuracy: 0.0700 - val_loss: 5.5471 - val_accuracy: 0.0050\n",
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8705 - accuracy: 0.0700 - val_loss: 5.5246 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8705 - accuracy: 0.0675 - val_loss: 5.5604 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8686 - accuracy: 0.0700 - val_loss: 5.5782 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8687 - accuracy: 0.0613 - val_loss: 5.5661 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.8667 - accuracy: 0.0725 - val_loss: 5.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8623 - accuracy: 0.0688 - val_loss: 5.5829 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8587 - accuracy: 0.0737 - val_loss: 5.5733 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8571 - accuracy: 0.0725 - val_loss: 5.5953 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8543 - accuracy: 0.0675 - val_loss: 5.5697 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8591 - accuracy: 0.0688 - val_loss: 5.5872 - val_accuracy: 0.0050\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8538 - accuracy: 0.0775 - val_loss: 5.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8550 - accuracy: 0.0675 - val_loss: 5.6214 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8698 - accuracy: 0.0613 - val_loss: 5.6241 - val_accuracy: 0.0050\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8689 - accuracy: 0.0650 - val_loss: 5.6087 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8504 - accuracy: 0.0662 - val_loss: 5.5845 - val_accuracy: 0.0050\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8450 - accuracy: 0.0688 - val_loss: 5.5917 - val_accuracy: 0.0050\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8422 - accuracy: 0.0700 - val_loss: 5.5847 - val_accuracy: 0.0050\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8420 - accuracy: 0.0750 - val_loss: 5.6116 - val_accuracy: 0.0050\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8406 - accuracy: 0.0712 - val_loss: 5.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8384 - accuracy: 0.0825 - val_loss: 5.6455 - val_accuracy: 0.0050\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8350 - accuracy: 0.0688 - val_loss: 5.6470 - val_accuracy: 0.0050\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8344 - accuracy: 0.0725 - val_loss: 5.6275 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8319 - accuracy: 0.0725 - val_loss: 5.6446 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8286 - accuracy: 0.0725 - val_loss: 5.6361 - val_accuracy: 0.0050\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8244 - accuracy: 0.0737 - val_loss: 5.6198 - val_accuracy: 0.0050\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8209 - accuracy: 0.0750 - val_loss: 5.6589 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8178 - accuracy: 0.0763 - val_loss: 5.6542 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8132 - accuracy: 0.0787 - val_loss: 5.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8117 - accuracy: 0.0763 - val_loss: 5.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8104 - accuracy: 0.0750 - val_loss: 5.6447 - val_accuracy: 0.0050\n",
      "Epoch 271/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8076 - accuracy: 0.0750 - val_loss: 5.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8044 - accuracy: 0.0812 - val_loss: 5.6562 - val_accuracy: 0.0050\n",
      "Epoch 273/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8037 - accuracy: 0.0775 - val_loss: 5.6993 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8007 - accuracy: 0.0800 - val_loss: 5.6920 - val_accuracy: 0.0050\n",
      "Epoch 275/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8005 - accuracy: 0.0812 - val_loss: 5.6678 - val_accuracy: 0.0050\n",
      "Epoch 276/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7967 - accuracy: 0.0862 - val_loss: 5.6951 - val_accuracy: 0.0050\n",
      "Epoch 277/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8019 - accuracy: 0.0787 - val_loss: 5.6902 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7976 - accuracy: 0.0725 - val_loss: 5.7211 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7945 - accuracy: 0.0812 - val_loss: 5.6824 - val_accuracy: 0.0050\n",
      "Epoch 280/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7955 - accuracy: 0.0775 - val_loss: 5.7377 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7911 - accuracy: 0.0800 - val_loss: 5.7055 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7856 - accuracy: 0.0800 - val_loss: 5.7290 - val_accuracy: 0.0050\n",
      "Epoch 283/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7843 - accuracy: 0.0838 - val_loss: 5.7351 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7775 - accuracy: 0.0775 - val_loss: 5.7232 - val_accuracy: 0.0050\n",
      "Epoch 285/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7740 - accuracy: 0.0787 - val_loss: 5.7496 - val_accuracy: 0.0100\n",
      "Epoch 286/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7686 - accuracy: 0.0887 - val_loss: 5.7443 - val_accuracy: 0.0050\n",
      "Epoch 287/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7667 - accuracy: 0.0825 - val_loss: 5.7359 - val_accuracy: 0.0050\n",
      "Epoch 288/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7653 - accuracy: 0.0900 - val_loss: 5.7669 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7621 - accuracy: 0.0850 - val_loss: 5.7754 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7601 - accuracy: 0.0800 - val_loss: 5.7569 - val_accuracy: 0.0050\n",
      "Epoch 291/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7604 - accuracy: 0.0787 - val_loss: 5.7545 - val_accuracy: 0.0050\n",
      "Epoch 292/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7569 - accuracy: 0.0812 - val_loss: 5.8028 - val_accuracy: 0.0050\n",
      "Epoch 293/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7534 - accuracy: 0.0800 - val_loss: 5.7766 - val_accuracy: 0.0100\n",
      "Epoch 294/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7518 - accuracy: 0.0775 - val_loss: 5.8020 - val_accuracy: 0.0050\n",
      "Epoch 295/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7467 - accuracy: 0.0887 - val_loss: 5.8186 - val_accuracy: 0.0050\n",
      "Epoch 296/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7486 - accuracy: 0.0862 - val_loss: 5.8054 - val_accuracy: 0.0100\n",
      "Epoch 297/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7534 - accuracy: 0.0800 - val_loss: 5.8556 - val_accuracy: 0.0050\n",
      "Epoch 298/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7554 - accuracy: 0.0825 - val_loss: 5.7869 - val_accuracy: 0.0050\n",
      "Epoch 299/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7501 - accuracy: 0.0763 - val_loss: 5.8311 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7505 - accuracy: 0.0800 - val_loss: 5.8439 - val_accuracy: 0.0050\n",
      "Epoch 301/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7437 - accuracy: 0.0825 - val_loss: 5.8063 - val_accuracy: 0.0050\n",
      "Epoch 302/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7383 - accuracy: 0.0850 - val_loss: 5.8299 - val_accuracy: 0.0050\n",
      "Epoch 303/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7365 - accuracy: 0.0887 - val_loss: 5.7941 - val_accuracy: 0.0050\n",
      "Epoch 304/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7423 - accuracy: 0.0825 - val_loss: 5.8119 - val_accuracy: 0.0050\n",
      "Epoch 305/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7322 - accuracy: 0.0825 - val_loss: 5.7995 - val_accuracy: 0.0050\n",
      "Epoch 306/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7276 - accuracy: 0.0838 - val_loss: 5.8116 - val_accuracy: 0.0050\n",
      "Epoch 307/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7224 - accuracy: 0.0850 - val_loss: 5.7849 - val_accuracy: 0.0100\n",
      "Epoch 308/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7199 - accuracy: 0.0850 - val_loss: 5.8111 - val_accuracy: 0.0100\n",
      "Epoch 309/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7153 - accuracy: 0.0913 - val_loss: 5.8367 - val_accuracy: 0.0100\n",
      "Epoch 310/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7159 - accuracy: 0.0862 - val_loss: 5.8525 - val_accuracy: 0.0050\n",
      "Epoch 311/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7114 - accuracy: 0.0913 - val_loss: 5.8553 - val_accuracy: 0.0100\n",
      "Epoch 312/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7054 - accuracy: 0.0988 - val_loss: 5.8358 - val_accuracy: 0.0050\n",
      "Epoch 313/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7027 - accuracy: 0.1013 - val_loss: 5.8683 - val_accuracy: 0.0050\n",
      "Epoch 314/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7011 - accuracy: 0.1000 - val_loss: 5.8270 - val_accuracy: 0.0100\n",
      "Epoch 315/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6990 - accuracy: 0.0962 - val_loss: 5.8518 - val_accuracy: 0.0100\n",
      "Epoch 316/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7001 - accuracy: 0.0938 - val_loss: 5.8736 - val_accuracy: 0.0050\n",
      "Epoch 317/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6962 - accuracy: 0.0975 - val_loss: 5.8722 - val_accuracy: 0.0050\n",
      "Epoch 318/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7006 - accuracy: 0.0900 - val_loss: 5.8638 - val_accuracy: 0.0050\n",
      "Epoch 319/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6917 - accuracy: 0.0925 - val_loss: 5.8476 - val_accuracy: 0.0100\n",
      "Epoch 320/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6878 - accuracy: 0.0975 - val_loss: 5.8944 - val_accuracy: 0.0100\n",
      "Epoch 321/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6872 - accuracy: 0.1025 - val_loss: 5.8921 - val_accuracy: 0.0050\n",
      "Epoch 322/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6828 - accuracy: 0.0938 - val_loss: 5.8852 - val_accuracy: 0.0100\n",
      "Epoch 323/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6802 - accuracy: 0.0988 - val_loss: 5.8922 - val_accuracy: 0.0050\n",
      "Epoch 324/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6791 - accuracy: 0.0900 - val_loss: 5.8957 - val_accuracy: 0.0100\n",
      "Epoch 325/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6770 - accuracy: 0.1013 - val_loss: 5.9127 - val_accuracy: 0.0050\n",
      "Epoch 326/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6743 - accuracy: 0.0962 - val_loss: 5.9097 - val_accuracy: 0.0050\n",
      "Epoch 327/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6724 - accuracy: 0.1013 - val_loss: 5.9192 - val_accuracy: 0.0050\n",
      "Epoch 328/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6751 - accuracy: 0.0925 - val_loss: 5.9382 - val_accuracy: 0.0050\n",
      "Epoch 329/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6743 - accuracy: 0.0950 - val_loss: 5.9195 - val_accuracy: 0.0050\n",
      "Epoch 330/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6740 - accuracy: 0.0862 - val_loss: 5.9503 - val_accuracy: 0.0050\n",
      "Epoch 331/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6771 - accuracy: 0.0875 - val_loss: 5.9802 - val_accuracy: 0.0050\n",
      "Epoch 332/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6791 - accuracy: 0.0838 - val_loss: 5.9506 - val_accuracy: 0.0050\n",
      "Epoch 333/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6754 - accuracy: 0.0925 - val_loss: 5.9399 - val_accuracy: 0.0150\n",
      "Epoch 334/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6674 - accuracy: 0.0913 - val_loss: 5.9405 - val_accuracy: 0.0050\n",
      "Epoch 335/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6608 - accuracy: 0.0925 - val_loss: 5.9569 - val_accuracy: 0.0100\n",
      "Epoch 336/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6581 - accuracy: 0.0975 - val_loss: 5.9654 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6563 - accuracy: 0.1013 - val_loss: 5.9535 - val_accuracy: 0.0100\n",
      "Epoch 338/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6530 - accuracy: 0.0887 - val_loss: 6.0000 - val_accuracy: 0.0100\n",
      "Epoch 339/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6515 - accuracy: 0.1013 - val_loss: 5.9638 - val_accuracy: 0.0100\n",
      "Epoch 340/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6484 - accuracy: 0.0938 - val_loss: 5.9943 - val_accuracy: 0.0050\n",
      "Epoch 341/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6443 - accuracy: 0.0988 - val_loss: 6.0000 - val_accuracy: 0.0100\n",
      "Epoch 342/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6448 - accuracy: 0.0988 - val_loss: 5.9908 - val_accuracy: 0.0050\n",
      "Epoch 343/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6402 - accuracy: 0.1025 - val_loss: 6.0144 - val_accuracy: 0.0050\n",
      "Epoch 344/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6379 - accuracy: 0.0975 - val_loss: 5.9953 - val_accuracy: 0.0100\n",
      "Epoch 345/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6354 - accuracy: 0.0975 - val_loss: 6.0201 - val_accuracy: 0.0050\n",
      "Epoch 346/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6363 - accuracy: 0.0925 - val_loss: 5.9976 - val_accuracy: 0.0100\n",
      "Epoch 347/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6301 - accuracy: 0.0962 - val_loss: 6.0051 - val_accuracy: 0.0100\n",
      "Epoch 348/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6326 - accuracy: 0.0975 - val_loss: 6.0455 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6307 - accuracy: 0.1013 - val_loss: 6.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6267 - accuracy: 0.0975 - val_loss: 6.0301 - val_accuracy: 0.0050\n",
      "Epoch 351/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6231 - accuracy: 0.1063 - val_loss: 6.0238 - val_accuracy: 0.0150\n",
      "Epoch 352/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6204 - accuracy: 0.1037 - val_loss: 6.0553 - val_accuracy: 0.0050\n",
      "Epoch 353/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6128 - accuracy: 0.1100 - val_loss: 6.0390 - val_accuracy: 0.0100\n",
      "Epoch 354/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6135 - accuracy: 0.1125 - val_loss: 6.0476 - val_accuracy: 0.0100\n",
      "Epoch 355/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6088 - accuracy: 0.1050 - val_loss: 6.0466 - val_accuracy: 0.0050\n",
      "Epoch 356/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6071 - accuracy: 0.1138 - val_loss: 6.0719 - val_accuracy: 0.0050\n",
      "Epoch 357/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6094 - accuracy: 0.1050 - val_loss: 6.0765 - val_accuracy: 0.0050\n",
      "Epoch 358/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6106 - accuracy: 0.1037 - val_loss: 6.0552 - val_accuracy: 0.0050\n",
      "Epoch 359/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6039 - accuracy: 0.1100 - val_loss: 6.0648 - val_accuracy: 0.0050\n",
      "Epoch 360/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6003 - accuracy: 0.1013 - val_loss: 6.1050 - val_accuracy: 0.0100\n",
      "Epoch 361/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6031 - accuracy: 0.1050 - val_loss: 6.0744 - val_accuracy: 0.0100\n",
      "Epoch 362/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6051 - accuracy: 0.1075 - val_loss: 6.1252 - val_accuracy: 0.0050\n",
      "Epoch 363/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6018 - accuracy: 0.1063 - val_loss: 6.0910 - val_accuracy: 0.0050\n",
      "Epoch 364/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6012 - accuracy: 0.0988 - val_loss: 6.1781 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5961 - accuracy: 0.1100 - val_loss: 6.1260 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5966 - accuracy: 0.1050 - val_loss: 6.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5941 - accuracy: 0.1050 - val_loss: 6.1490 - val_accuracy: 0.0100\n",
      "Epoch 368/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5860 - accuracy: 0.1050 - val_loss: 6.1350 - val_accuracy: 0.0050\n",
      "Epoch 369/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5810 - accuracy: 0.1050 - val_loss: 6.1244 - val_accuracy: 0.0050\n",
      "Epoch 370/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5802 - accuracy: 0.1037 - val_loss: 6.1600 - val_accuracy: 0.0100\n",
      "Epoch 371/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5780 - accuracy: 0.1013 - val_loss: 6.1616 - val_accuracy: 0.0050\n",
      "Epoch 372/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5760 - accuracy: 0.1075 - val_loss: 6.1495 - val_accuracy: 0.0050\n",
      "Epoch 373/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5722 - accuracy: 0.1138 - val_loss: 6.1547 - val_accuracy: 0.0050\n",
      "Epoch 374/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5782 - accuracy: 0.1037 - val_loss: 6.1701 - val_accuracy: 0.0050\n",
      "Epoch 375/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5795 - accuracy: 0.1050 - val_loss: 6.1967 - val_accuracy: 0.0100\n",
      "Epoch 376/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5747 - accuracy: 0.1063 - val_loss: 6.2103 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5708 - accuracy: 0.1112 - val_loss: 6.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5668 - accuracy: 0.1025 - val_loss: 6.2055 - val_accuracy: 0.0100\n",
      "Epoch 379/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5652 - accuracy: 0.1075 - val_loss: 6.2001 - val_accuracy: 0.0100\n",
      "Epoch 380/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5609 - accuracy: 0.1050 - val_loss: 6.2225 - val_accuracy: 0.0100\n",
      "Epoch 381/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5670 - accuracy: 0.1037 - val_loss: 6.2053 - val_accuracy: 0.0100\n",
      "Epoch 382/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5646 - accuracy: 0.1112 - val_loss: 6.2603 - val_accuracy: 0.0050\n",
      "Epoch 383/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5619 - accuracy: 0.1050 - val_loss: 6.2518 - val_accuracy: 0.0050\n",
      "Epoch 384/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5640 - accuracy: 0.1112 - val_loss: 6.2224 - val_accuracy: 0.0100\n",
      "Epoch 385/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5587 - accuracy: 0.1075 - val_loss: 6.2713 - val_accuracy: 0.0050\n",
      "Epoch 386/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5538 - accuracy: 0.1112 - val_loss: 6.2593 - val_accuracy: 0.0050\n",
      "Epoch 387/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5478 - accuracy: 0.1125 - val_loss: 6.2431 - val_accuracy: 0.0150\n",
      "Epoch 388/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5440 - accuracy: 0.1112 - val_loss: 6.2516 - val_accuracy: 0.0050\n",
      "Epoch 389/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5426 - accuracy: 0.1100 - val_loss: 6.2877 - val_accuracy: 0.0050\n",
      "Epoch 390/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5382 - accuracy: 0.1175 - val_loss: 6.2731 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5372 - accuracy: 0.1112 - val_loss: 6.2818 - val_accuracy: 0.0050\n",
      "Epoch 392/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5343 - accuracy: 0.1238 - val_loss: 6.2952 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5313 - accuracy: 0.1187 - val_loss: 6.3049 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5309 - accuracy: 0.1138 - val_loss: 6.3319 - val_accuracy: 0.0050\n",
      "Epoch 395/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5357 - accuracy: 0.1037 - val_loss: 6.3136 - val_accuracy: 0.0050\n",
      "Epoch 396/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5289 - accuracy: 0.1138 - val_loss: 6.3103 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5247 - accuracy: 0.1075 - val_loss: 6.3508 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5253 - accuracy: 0.1163 - val_loss: 6.3147 - val_accuracy: 0.0050\n",
      "Epoch 399/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5250 - accuracy: 0.1037 - val_loss: 6.3704 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5268 - accuracy: 0.1225 - val_loss: 6.3390 - val_accuracy: 0.0050\n",
      "Epoch 401/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5276 - accuracy: 0.1125 - val_loss: 6.3484 - val_accuracy: 0.0050\n",
      "Epoch 402/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5269 - accuracy: 0.1125 - val_loss: 6.3114 - val_accuracy: 0.0100\n",
      "Epoch 403/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5277 - accuracy: 0.1013 - val_loss: 6.3924 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.5244 - accuracy: 0.1075 - val_loss: 6.4059 - val_accuracy: 0.0050\n",
      "Epoch 405/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5204 - accuracy: 0.1100 - val_loss: 6.3455 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5146 - accuracy: 0.1088 - val_loss: 6.3581 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5155 - accuracy: 0.1163 - val_loss: 6.4012 - val_accuracy: 0.0050\n",
      "Epoch 408/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5116 - accuracy: 0.1213 - val_loss: 6.4004 - val_accuracy: 0.0050\n",
      "Epoch 409/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5075 - accuracy: 0.1125 - val_loss: 6.4261 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5083 - accuracy: 0.1150 - val_loss: 6.3696 - val_accuracy: 0.0050\n",
      "Epoch 411/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5020 - accuracy: 0.1175 - val_loss: 6.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5023 - accuracy: 0.1213 - val_loss: 6.4045 - val_accuracy: 0.0050\n",
      "Epoch 413/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5034 - accuracy: 0.1100 - val_loss: 6.4555 - val_accuracy: 0.0050\n",
      "Epoch 414/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5034 - accuracy: 0.1163 - val_loss: 6.4252 - val_accuracy: 0.0050\n",
      "Epoch 415/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4977 - accuracy: 0.1150 - val_loss: 6.4129 - val_accuracy: 0.0100\n",
      "Epoch 416/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4965 - accuracy: 0.1175 - val_loss: 6.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4935 - accuracy: 0.1150 - val_loss: 6.4589 - val_accuracy: 0.0050\n",
      "Epoch 418/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4944 - accuracy: 0.1100 - val_loss: 6.4349 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4980 - accuracy: 0.1213 - val_loss: 6.5181 - val_accuracy: 0.0050\n",
      "Epoch 420/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4965 - accuracy: 0.1125 - val_loss: 6.5046 - val_accuracy: 0.0050\n",
      "Epoch 421/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4925 - accuracy: 0.1150 - val_loss: 6.4700 - val_accuracy: 0.0050\n",
      "Epoch 422/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4834 - accuracy: 0.1187 - val_loss: 6.4984 - val_accuracy: 0.0050\n",
      "Epoch 423/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4820 - accuracy: 0.1200 - val_loss: 6.4920 - val_accuracy: 0.0050\n",
      "Epoch 424/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4775 - accuracy: 0.1213 - val_loss: 6.4982 - val_accuracy: 0.0050\n",
      "Epoch 425/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4740 - accuracy: 0.1213 - val_loss: 6.4968 - val_accuracy: 0.0050\n",
      "Epoch 426/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4678 - accuracy: 0.1312 - val_loss: 6.5566 - val_accuracy: 0.0050\n",
      "Epoch 427/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4722 - accuracy: 0.1200 - val_loss: 6.5081 - val_accuracy: 0.0100\n",
      "Epoch 428/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4735 - accuracy: 0.1200 - val_loss: 6.5334 - val_accuracy: 0.0050\n",
      "Epoch 429/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4697 - accuracy: 0.1125 - val_loss: 6.5750 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4649 - accuracy: 0.1300 - val_loss: 6.5650 - val_accuracy: 0.0050\n",
      "Epoch 431/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4623 - accuracy: 0.1213 - val_loss: 6.5766 - val_accuracy: 0.0050\n",
      "Epoch 432/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4696 - accuracy: 0.1125 - val_loss: 6.5575 - val_accuracy: 0.0050\n",
      "Epoch 433/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4664 - accuracy: 0.1150 - val_loss: 6.6337 - val_accuracy: 0.0050\n",
      "Epoch 434/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4663 - accuracy: 0.1125 - val_loss: 6.5706 - val_accuracy: 0.0100\n",
      "Epoch 435/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4598 - accuracy: 0.1138 - val_loss: 6.6335 - val_accuracy: 0.0100\n",
      "Epoch 436/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4523 - accuracy: 0.1150 - val_loss: 6.6469 - val_accuracy: 0.0050\n",
      "Epoch 437/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4582 - accuracy: 0.1138 - val_loss: 6.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4594 - accuracy: 0.1125 - val_loss: 6.6320 - val_accuracy: 0.0100\n",
      "Epoch 439/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4528 - accuracy: 0.1225 - val_loss: 6.5918 - val_accuracy: 0.0050\n",
      "Epoch 440/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4428 - accuracy: 0.1275 - val_loss: 6.6183 - val_accuracy: 0.0050\n",
      "Epoch 441/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4404 - accuracy: 0.1312 - val_loss: 6.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4372 - accuracy: 0.1225 - val_loss: 6.6273 - val_accuracy: 0.0050\n",
      "Epoch 443/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4364 - accuracy: 0.1250 - val_loss: 6.6463 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4350 - accuracy: 0.1250 - val_loss: 6.6755 - val_accuracy: 0.0050\n",
      "Epoch 445/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4317 - accuracy: 0.1250 - val_loss: 6.6630 - val_accuracy: 0.0050\n",
      "Epoch 446/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4274 - accuracy: 0.1275 - val_loss: 6.6588 - val_accuracy: 0.0100\n",
      "Epoch 447/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4229 - accuracy: 0.1325 - val_loss: 6.6836 - val_accuracy: 0.0100\n",
      "Epoch 448/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4211 - accuracy: 0.1300 - val_loss: 6.6809 - val_accuracy: 0.0100\n",
      "Epoch 449/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4183 - accuracy: 0.1300 - val_loss: 6.6991 - val_accuracy: 0.0100\n",
      "Epoch 450/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4174 - accuracy: 0.1300 - val_loss: 6.6761 - val_accuracy: 0.0050\n",
      "Epoch 451/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4183 - accuracy: 0.1250 - val_loss: 6.7157 - val_accuracy: 0.0100\n",
      "Epoch 452/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4177 - accuracy: 0.1338 - val_loss: 6.7288 - val_accuracy: 0.0100\n",
      "Epoch 453/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4160 - accuracy: 0.1287 - val_loss: 6.7382 - val_accuracy: 0.0050\n",
      "Epoch 454/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4124 - accuracy: 0.1312 - val_loss: 6.7594 - val_accuracy: 0.0100\n",
      "Epoch 455/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4127 - accuracy: 0.1200 - val_loss: 6.7492 - val_accuracy: 0.0100\n",
      "Epoch 456/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4091 - accuracy: 0.1325 - val_loss: 6.7608 - val_accuracy: 0.0050\n",
      "Epoch 457/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4089 - accuracy: 0.1350 - val_loss: 6.7434 - val_accuracy: 0.0050\n",
      "Epoch 458/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4080 - accuracy: 0.1375 - val_loss: 6.7419 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4108 - accuracy: 0.1250 - val_loss: 6.7832 - val_accuracy: 0.0100\n",
      "Epoch 460/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4110 - accuracy: 0.1225 - val_loss: 6.7599 - val_accuracy: 0.0050\n",
      "Epoch 461/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4090 - accuracy: 0.1287 - val_loss: 6.8095 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4117 - accuracy: 0.1250 - val_loss: 6.8274 - val_accuracy: 0.0050\n",
      "Epoch 463/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4183 - accuracy: 0.1275 - val_loss: 6.8191 - val_accuracy: 0.0050\n",
      "Epoch 464/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4157 - accuracy: 0.1150 - val_loss: 6.7670 - val_accuracy: 0.0050\n",
      "Epoch 465/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4052 - accuracy: 0.1250 - val_loss: 6.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4049 - accuracy: 0.1225 - val_loss: 6.7901 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4059 - accuracy: 0.1187 - val_loss: 6.8054 - val_accuracy: 0.0100\n",
      "Epoch 468/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3974 - accuracy: 0.1238 - val_loss: 6.7573 - val_accuracy: 0.0100\n",
      "Epoch 469/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3972 - accuracy: 0.1250 - val_loss: 6.8590 - val_accuracy: 0.0050\n",
      "Epoch 470/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3921 - accuracy: 0.1250 - val_loss: 6.8357 - val_accuracy: 0.0050\n",
      "Epoch 471/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3871 - accuracy: 0.1238 - val_loss: 6.8409 - val_accuracy: 0.0050\n",
      "Epoch 472/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3821 - accuracy: 0.1262 - val_loss: 6.8181 - val_accuracy: 0.0100\n",
      "Epoch 473/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3800 - accuracy: 0.1388 - val_loss: 6.8282 - val_accuracy: 0.0050\n",
      "Epoch 474/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3826 - accuracy: 0.1262 - val_loss: 6.8539 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3843 - accuracy: 0.1338 - val_loss: 6.8609 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3845 - accuracy: 0.1275 - val_loss: 6.8684 - val_accuracy: 0.0050\n",
      "Epoch 477/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3923 - accuracy: 0.1238 - val_loss: 6.9006 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3847 - accuracy: 0.1163 - val_loss: 6.8530 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3793 - accuracy: 0.1325 - val_loss: 6.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3775 - accuracy: 0.1300 - val_loss: 6.9224 - val_accuracy: 0.0100\n",
      "Epoch 481/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.3767 - accuracy: 0.1250 - val_loss: 6.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3711 - accuracy: 0.1350 - val_loss: 6.8951 - val_accuracy: 0.0050\n",
      "Epoch 483/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3728 - accuracy: 0.1300 - val_loss: 6.8964 - val_accuracy: 0.0100\n",
      "Epoch 484/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3708 - accuracy: 0.1325 - val_loss: 6.9323 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3708 - accuracy: 0.1275 - val_loss: 6.9352 - val_accuracy: 0.0100\n",
      "Epoch 486/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3668 - accuracy: 0.1275 - val_loss: 6.9124 - val_accuracy: 0.0050\n",
      "Epoch 487/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3713 - accuracy: 0.1300 - val_loss: 6.9747 - val_accuracy: 0.0100\n",
      "Epoch 488/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3669 - accuracy: 0.1150 - val_loss: 6.9453 - val_accuracy: 0.0050\n",
      "Epoch 489/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3589 - accuracy: 0.1412 - val_loss: 6.9874 - val_accuracy: 0.0100\n",
      "Epoch 490/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3604 - accuracy: 0.1287 - val_loss: 6.9622 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3544 - accuracy: 0.1350 - val_loss: 6.9697 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.3510 - accuracy: 0.1363 - val_loss: 6.9795 - val_accuracy: 0.0100\n",
      "Epoch 493/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3479 - accuracy: 0.1375 - val_loss: 6.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3455 - accuracy: 0.1388 - val_loss: 6.9910 - val_accuracy: 0.0150\n",
      "Epoch 495/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3458 - accuracy: 0.1363 - val_loss: 7.0076 - val_accuracy: 0.0050\n",
      "Epoch 496/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3473 - accuracy: 0.1325 - val_loss: 7.0328 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.3444 - accuracy: 0.1350 - val_loss: 7.0302 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3450 - accuracy: 0.1312 - val_loss: 7.0461 - val_accuracy: 0.0100\n",
      "Epoch 499/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3486 - accuracy: 0.1325 - val_loss: 7.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3548 - accuracy: 0.1275 - val_loss: 7.0213 - val_accuracy: 0.0100\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(FIRST_LAYER, input_shape=(100,), activation=ACTIVATION_1)) # Assuming 100 features\n",
    "model.add(Dense(SECOND_LAYER, activation=ACTIVATION_2))\n",
    "model.add(Dense(num_classes, activation=ACTIVATION_OUT)) # num_classes is the number of unique breed labels\n",
    "model.compile(optimizer=Adam(learning_rate=LEARN_RATE), loss=LOSS_TYPE, metrics=METRICS)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80d1b997-4437-4ad5-ba4e-008b127f9067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0213 - accuracy: 0.0100\n",
      "Test Accuracy: 0.009999999776482582\n",
      "Confusion Matrix for each label : \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#print(\"Accuracy : \", accuracy_score(y_test, y_pred))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#print(\"Mean Square Error : \", mean_squared_error(y_test, y_pred))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix for each label : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:508\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    399\u001b[0m     {\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    409\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplewise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    410\u001b[0m ):\n\u001b[0;32m    411\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;124;03m            [1, 2]]])\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     96\u001b[0m             type_true, type_pred\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "#print(\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
    "#print(\"Mean Square Error : \", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78860532-2cbd-4112-b51c-f0de5f5c1539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
