{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c480d74a-d567-46ac-812c-a790df98caa7",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7599a31-d302-46c6-a558-35b7d3a2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bc7f72-631e-48c0-9b9d-909224a60244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\kirin\\miniconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: keras in c:\\users\\kirin\\miniconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikeras) (23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikeras) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikeras) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kirin\\miniconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd374a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200cbb76-e40c-4f79-aef7-404b7e0777f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 90</th>\n",
       "      <th>Feature 91</th>\n",
       "      <th>Feature 92</th>\n",
       "      <th>Feature 93</th>\n",
       "      <th>Feature 94</th>\n",
       "      <th>Feature 95</th>\n",
       "      <th>Feature 96</th>\n",
       "      <th>Feature 97</th>\n",
       "      <th>Feature 98</th>\n",
       "      <th>Feature 99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>-5.279870</td>\n",
       "      <td>-2.208426</td>\n",
       "      <td>5.211814</td>\n",
       "      <td>-8.099501</td>\n",
       "      <td>-13.185220</td>\n",
       "      <td>-0.753768</td>\n",
       "      <td>-3.015471</td>\n",
       "      <td>0.825370</td>\n",
       "      <td>-4.269372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465695</td>\n",
       "      <td>-0.674558</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>-1.240681</td>\n",
       "      <td>-1.069499</td>\n",
       "      <td>-0.714136</td>\n",
       "      <td>1.011624</td>\n",
       "      <td>-0.225715</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>1.140998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>0.524020</td>\n",
       "      <td>-4.321692</td>\n",
       "      <td>-5.808849</td>\n",
       "      <td>-0.097443</td>\n",
       "      <td>-13.157566</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>-4.521323</td>\n",
       "      <td>-1.382092</td>\n",
       "      <td>-1.304059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410429</td>\n",
       "      <td>0.396908</td>\n",
       "      <td>0.344853</td>\n",
       "      <td>0.243527</td>\n",
       "      <td>-0.416206</td>\n",
       "      <td>0.310021</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>-0.221647</td>\n",
       "      <td>-0.306602</td>\n",
       "      <td>-0.855617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>4.484349</td>\n",
       "      <td>-11.409184</td>\n",
       "      <td>-2.061785</td>\n",
       "      <td>-8.795961</td>\n",
       "      <td>-10.736951</td>\n",
       "      <td>-0.650287</td>\n",
       "      <td>0.697348</td>\n",
       "      <td>8.464226</td>\n",
       "      <td>-2.961214</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.486026</td>\n",
       "      <td>0.636264</td>\n",
       "      <td>-0.315544</td>\n",
       "      <td>1.400241</td>\n",
       "      <td>-0.116869</td>\n",
       "      <td>-0.253275</td>\n",
       "      <td>0.918089</td>\n",
       "      <td>-0.645903</td>\n",
       "      <td>0.545067</td>\n",
       "      <td>-1.274210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>8.630311</td>\n",
       "      <td>-9.028896</td>\n",
       "      <td>-4.177602</td>\n",
       "      <td>-3.575223</td>\n",
       "      <td>-7.698362</td>\n",
       "      <td>-5.857273</td>\n",
       "      <td>-3.473359</td>\n",
       "      <td>6.915802</td>\n",
       "      <td>1.972978</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.718268</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.152345</td>\n",
       "      <td>0.562226</td>\n",
       "      <td>0.279578</td>\n",
       "      <td>-0.277104</td>\n",
       "      <td>-0.956852</td>\n",
       "      <td>-0.531012</td>\n",
       "      <td>0.249064</td>\n",
       "      <td>-1.877944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>-6.459163</td>\n",
       "      <td>-5.178344</td>\n",
       "      <td>3.182314</td>\n",
       "      <td>-6.884826</td>\n",
       "      <td>-2.663270</td>\n",
       "      <td>-0.779802</td>\n",
       "      <td>-0.788943</td>\n",
       "      <td>4.521932</td>\n",
       "      <td>-3.636744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.964177</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>-0.274313</td>\n",
       "      <td>-0.534803</td>\n",
       "      <td>0.797063</td>\n",
       "      <td>-0.156896</td>\n",
       "      <td>1.027882</td>\n",
       "      <td>1.130965</td>\n",
       "      <td>0.696718</td>\n",
       "      <td>0.098893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Breed  Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0  brittany_spaniel  -5.279870  -2.208426   5.211814  -8.099501 -13.185220   \n",
       "1  brittany_spaniel   0.524020  -4.321692  -5.808849  -0.097443 -13.157566   \n",
       "2  brittany_spaniel   4.484349 -11.409184  -2.061785  -8.795961 -10.736951   \n",
       "3  brittany_spaniel   8.630311  -9.028896  -4.177602  -3.575223  -7.698362   \n",
       "4  brittany_spaniel  -6.459163  -5.178344   3.182314  -6.884826  -2.663270   \n",
       "\n",
       "   Feature 5  Feature 6  Feature 7  Feature 8  ...  Feature 90  Feature 91  \\\n",
       "0  -0.753768  -3.015471   0.825370  -4.269372  ...   -0.465695   -0.674558   \n",
       "1   0.439865  -4.521323  -1.382092  -1.304059  ...   -0.410429    0.396908   \n",
       "2  -0.650287   0.697348   8.464226  -2.961214  ...   -1.486026    0.636264   \n",
       "3  -5.857273  -3.473359   6.915802   1.972978  ...   -1.718268    0.056995   \n",
       "4  -0.779802  -0.788943   4.521932  -3.636744  ...   -0.964177    0.368517   \n",
       "\n",
       "   Feature 92  Feature 93  Feature 94  Feature 95  Feature 96  Feature 97  \\\n",
       "0    0.123558   -1.240681   -1.069499   -0.714136    1.011624   -0.225715   \n",
       "1    0.344853    0.243527   -0.416206    0.310021    0.025371   -0.221647   \n",
       "2   -0.315544    1.400241   -0.116869   -0.253275    0.918089   -0.645903   \n",
       "3    0.152345    0.562226    0.279578   -0.277104   -0.956852   -0.531012   \n",
       "4   -0.274313   -0.534803    0.797063   -0.156896    1.027882    1.130965   \n",
       "\n",
       "   Feature 98  Feature 99  \n",
       "0   -0.220330    1.140998  \n",
       "1   -0.306602   -0.855617  \n",
       "2    0.545067   -1.274210  \n",
       "3    0.249064   -1.877944  \n",
       "4    0.696718    0.098893  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Breeds: 120\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv')\n",
    "\n",
    "x = df.drop(columns = ['Breed'])\n",
    "y = df['Breed']\n",
    "num_classes = 120\n",
    "display(df.head())\n",
    "print(f\"Number of Breeds: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84336ead-25d3-401b-9e0e-311c35f29391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "# TEST_SIZE = 0.4\n",
    "# LEARN_RATE = 0.001\n",
    "# FIRST_LAYER = 128 \n",
    "# ACTIVATION_1 = 'relu'\n",
    "# SECOND_LAYER = 64\n",
    "# ACTIVATION_2 = 'relu'\n",
    "# ACTIVATION_OUT = 'softmax'\n",
    "# LOSS_TYPE = 'categorical_crossentropy'\n",
    "# METRICS = ['accuracy']\n",
    "# EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc74830-7385-4568-bab2-f09f4a41df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'first_layer': [2, 4, 8, 32, 64, 128],\n",
    "    'second_layer': [4, 16, 32, 64],\n",
    "    'activation_1': ['relu', 'tanh'],\n",
    "    'activation_2': ['relu', 'tanh'],\n",
    "    'activation_out': ['softmax'],\n",
    "    'learn_rate': [0.0001, 0.0005, 0.001, 0.005, .01],\n",
    "    'batch_size' : [20, 50, 100],\n",
    "    'epochs' : [10, 20]\n",
    "}\n",
    "ACTIVATION_1 = 'relu'\n",
    "ACTIVATION_2 = 'relu'\n",
    "ACTIVATION_OUT = 'softmax'\n",
    "TEST_SIZE = 0.3\n",
    "EPOCHS = 20\n",
    "METRICS = ['accuracy']\n",
    "LOSS_TYPE = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0facdc-6b55-44b7-9e58-cd09912f0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Breed'])\n",
    "y = df['Breed']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = TEST_SIZE)\n",
    "\n",
    "# Encode the categorical target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the encoded labels to one-hot encoding\n",
    "y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11822a6-d107-4ba2-b268-e31efe07dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.9880 - accuracy: 0.5239 - val_loss: 0.9151 - val_accuracy: 0.7279\n",
      "Epoch 2/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.7745 - val_loss: 0.7884 - val_accuracy: 0.7575\n",
      "Epoch 3/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.8220 - val_loss: 0.7817 - val_accuracy: 0.7538\n",
      "Epoch 4/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.8402 - val_loss: 0.7509 - val_accuracy: 0.7660\n",
      "Epoch 5/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.4180 - accuracy: 0.8649 - val_loss: 0.7834 - val_accuracy: 0.7699\n",
      "Epoch 6/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8797 - val_loss: 0.7850 - val_accuracy: 0.7697\n",
      "Epoch 7/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8928 - val_loss: 0.7924 - val_accuracy: 0.7720\n",
      "Epoch 8/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.9056 - val_loss: 0.8511 - val_accuracy: 0.7649\n",
      "Epoch 9/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.2662 - accuracy: 0.9118 - val_loss: 0.8362 - val_accuracy: 0.7706\n",
      "Epoch 10/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9227 - val_loss: 0.8897 - val_accuracy: 0.7660\n",
      "Epoch 11/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.2099 - accuracy: 0.9281 - val_loss: 0.9329 - val_accuracy: 0.7616\n",
      "Epoch 12/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9404 - val_loss: 0.9356 - val_accuracy: 0.7666\n",
      "Epoch 13/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9465 - val_loss: 0.9836 - val_accuracy: 0.7660\n",
      "Epoch 14/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9498 - val_loss: 1.0384 - val_accuracy: 0.7638\n",
      "Epoch 15/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.1294 - accuracy: 0.9577 - val_loss: 1.1020 - val_accuracy: 0.7605\n",
      "Epoch 16/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9625 - val_loss: 1.1605 - val_accuracy: 0.7534\n",
      "Epoch 17/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.9674 - val_loss: 1.1548 - val_accuracy: 0.7613\n",
      "Epoch 18/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9702 - val_loss: 1.1995 - val_accuracy: 0.7586\n",
      "Epoch 19/20\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 0.0837 - accuracy: 0.9735 - val_loss: 1.2413 - val_accuracy: 0.7539\n",
      "Epoch 20/20\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 1.3225 - val_accuracy: 0.7494\n",
      "256/256 [==============================] - 0s 624us/step\n"
     ]
    }
   ],
   "source": [
    "def create_model(first_layer=128, activation_1='relu', second_layer=64, activation_2='relu', activation_out='softmax', learn_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_layer, input_shape=(100,), activation=activation_1))\n",
    "    model.add(Dense(second_layer, activation=activation_2))\n",
    "    model.add(Dense(num_classes, activation=activation_out))\n",
    "    model.compile(optimizer=Adam(learning_rate=learn_rate), loss=LOSS_TYPE, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d1b997-4437-4ad5-ba4e-008b127f9067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 0s 690us/step - loss: 1.3225 - accuracy: 0.7494\n",
      "Test Accuracy: 0.7493881583213806\n",
      "Confusion Matrix for each label : \n",
      "[[[8098   11]\n",
      "  [  11   52]]\n",
      "\n",
      " [[8074    4]\n",
      "  [  14   80]]\n",
      "\n",
      " [[8109    3]\n",
      "  [   4   56]]\n",
      "\n",
      " [[8070   18]\n",
      "  [  17   67]]\n",
      "\n",
      " [[8046   50]\n",
      "  [  19   57]]\n",
      "\n",
      " [[8086   21]\n",
      "  [  23   42]]\n",
      "\n",
      " [[8078    9]\n",
      "  [  39   46]]\n",
      "\n",
      " [[8077   16]\n",
      "  [  18   61]]\n",
      "\n",
      " [[8080   25]\n",
      "  [  18   49]]\n",
      "\n",
      " [[8067   28]\n",
      "  [  26   51]]\n",
      "\n",
      " [[8100    6]\n",
      "  [   4   62]]\n",
      "\n",
      " [[8080   12]\n",
      "  [   5   75]]\n",
      "\n",
      " [[8082   11]\n",
      "  [   4   75]]\n",
      "\n",
      " [[8081   16]\n",
      "  [  17   58]]\n",
      "\n",
      " [[8093   10]\n",
      "  [   7   62]]\n",
      "\n",
      " [[8104    6]\n",
      "  [  41   21]]\n",
      "\n",
      " [[8089    5]\n",
      "  [  15   63]]\n",
      "\n",
      " [[8106    5]\n",
      "  [  23   38]]\n",
      "\n",
      " [[8092   10]\n",
      "  [  13   57]]\n",
      "\n",
      " [[8075   42]\n",
      "  [   8   47]]\n",
      "\n",
      " [[8106    8]\n",
      "  [  14   44]]\n",
      "\n",
      " [[8100   18]\n",
      "  [   3   51]]\n",
      "\n",
      " [[8091    9]\n",
      "  [  30   42]]\n",
      "\n",
      " [[8101    7]\n",
      "  [  25   39]]\n",
      "\n",
      " [[8093   15]\n",
      "  [  11   53]]\n",
      "\n",
      " [[8084    7]\n",
      "  [  32   49]]\n",
      "\n",
      " [[8070   48]\n",
      "  [  13   41]]\n",
      "\n",
      " [[8091   19]\n",
      "  [   8   54]]\n",
      "\n",
      " [[8103   13]\n",
      "  [  19   37]]\n",
      "\n",
      " [[8087    9]\n",
      "  [   2   74]]\n",
      "\n",
      " [[8112   11]\n",
      "  [   4   45]]\n",
      "\n",
      " [[8094   12]\n",
      "  [  21   45]]\n",
      "\n",
      " [[8076   33]\n",
      "  [  13   50]]\n",
      "\n",
      " [[8086   14]\n",
      "  [  24   48]]\n",
      "\n",
      " [[8057   56]\n",
      "  [  16   43]]\n",
      "\n",
      " [[8088    8]\n",
      "  [  21   55]]\n",
      "\n",
      " [[8097   15]\n",
      "  [   5   55]]\n",
      "\n",
      " [[8094    4]\n",
      "  [  24   50]]\n",
      "\n",
      " [[8104   11]\n",
      "  [  30   27]]\n",
      "\n",
      " [[8079   29]\n",
      "  [  18   46]]\n",
      "\n",
      " [[8061   34]\n",
      "  [  12   65]]\n",
      "\n",
      " [[8093   20]\n",
      "  [  12   47]]\n",
      "\n",
      " [[8077   21]\n",
      "  [  18   56]]\n",
      "\n",
      " [[8070   32]\n",
      "  [  39   31]]\n",
      "\n",
      " [[8101   12]\n",
      "  [  12   47]]\n",
      "\n",
      " [[8101   12]\n",
      "  [  10   49]]\n",
      "\n",
      " [[8073   29]\n",
      "  [  22   48]]\n",
      "\n",
      " [[8112    6]\n",
      "  [  10   44]]\n",
      "\n",
      " [[8094    9]\n",
      "  [   7   62]]\n",
      "\n",
      " [[8091   17]\n",
      "  [  26   38]]\n",
      "\n",
      " [[8070   18]\n",
      "  [  18   66]]\n",
      "\n",
      " [[8101    9]\n",
      "  [  19   43]]\n",
      "\n",
      " [[8110    3]\n",
      "  [   6   53]]\n",
      "\n",
      " [[8101   11]\n",
      "  [  25   35]]\n",
      "\n",
      " [[8102    4]\n",
      "  [  20   46]]\n",
      "\n",
      " [[8077   18]\n",
      "  [  13   64]]\n",
      "\n",
      " [[8101    4]\n",
      "  [   9   58]]\n",
      "\n",
      " [[8104    9]\n",
      "  [  21   38]]\n",
      "\n",
      " [[8103    4]\n",
      "  [  11   54]]\n",
      "\n",
      " [[8055   13]\n",
      "  [  52   52]]\n",
      "\n",
      " [[8099   14]\n",
      "  [  18   41]]\n",
      "\n",
      " [[8090    1]\n",
      "  [  28   53]]\n",
      "\n",
      " [[8103    0]\n",
      "  [   4   65]]\n",
      "\n",
      " [[8065   50]\n",
      "  [  13   44]]\n",
      "\n",
      " [[8094    6]\n",
      "  [  11   61]]\n",
      "\n",
      " [[8104    1]\n",
      "  [   5   62]]\n",
      "\n",
      " [[8101   17]\n",
      "  [   7   47]]\n",
      "\n",
      " [[8082   27]\n",
      "  [  19   44]]\n",
      "\n",
      " [[8067   33]\n",
      "  [  18   54]]\n",
      "\n",
      " [[8076    9]\n",
      "  [   6   81]]\n",
      "\n",
      " [[8047   59]\n",
      "  [  27   39]]\n",
      "\n",
      " [[8080   18]\n",
      "  [  23   51]]\n",
      "\n",
      " [[8115    5]\n",
      "  [   7   45]]\n",
      "\n",
      " [[8051   15]\n",
      "  [  23   83]]\n",
      "\n",
      " [[8093    6]\n",
      "  [  10   63]]\n",
      "\n",
      " [[8068   31]\n",
      "  [  14   59]]\n",
      "\n",
      " [[8096   20]\n",
      "  [  41   15]]\n",
      "\n",
      " [[8088   23]\n",
      "  [  22   39]]\n",
      "\n",
      " [[8058   40]\n",
      "  [  16   58]]\n",
      "\n",
      " [[8077   24]\n",
      "  [  31   40]]\n",
      "\n",
      " [[8086    5]\n",
      "  [   3   78]]\n",
      "\n",
      " [[8061   37]\n",
      "  [  17   57]]\n",
      "\n",
      " [[8092    7]\n",
      "  [  14   59]]\n",
      "\n",
      " [[8099   13]\n",
      "  [  15   45]]\n",
      "\n",
      " [[8084   18]\n",
      "  [   1   69]]\n",
      "\n",
      " [[8085   33]\n",
      "  [   9   45]]\n",
      "\n",
      " [[8085    8]\n",
      "  [  40   39]]\n",
      "\n",
      " [[8077   13]\n",
      "  [   3   79]]\n",
      "\n",
      " [[8093    6]\n",
      "  [  10   63]]\n",
      "\n",
      " [[8097   18]\n",
      "  [  14   43]]\n",
      "\n",
      " [[8085   19]\n",
      "  [  27   41]]\n",
      "\n",
      " [[8114    2]\n",
      "  [  12   44]]\n",
      "\n",
      " [[8106    4]\n",
      "  [   5   57]]\n",
      "\n",
      " [[8076   10]\n",
      "  [  17   69]]\n",
      "\n",
      " [[8074   16]\n",
      "  [   8   74]]\n",
      "\n",
      " [[8107   10]\n",
      "  [   6   49]]\n",
      "\n",
      " [[8089    7]\n",
      "  [  20   56]]\n",
      "\n",
      " [[8027   51]\n",
      "  [  12   82]]\n",
      "\n",
      " [[8084    8]\n",
      "  [  10   70]]\n",
      "\n",
      " [[8102   11]\n",
      "  [  28   31]]\n",
      "\n",
      " [[8054   35]\n",
      "  [  42   41]]\n",
      "\n",
      " [[8037   55]\n",
      "  [  14   66]]\n",
      "\n",
      " [[8089   14]\n",
      "  [  32   37]]\n",
      "\n",
      " [[8069   40]\n",
      "  [  12   51]]\n",
      "\n",
      " [[8079   36]\n",
      "  [  26   31]]\n",
      "\n",
      " [[8109    2]\n",
      "  [   8   53]]\n",
      "\n",
      " [[8098   11]\n",
      "  [  12   51]]\n",
      "\n",
      " [[8097   12]\n",
      "  [  18   45]]\n",
      "\n",
      " [[8038   46]\n",
      "  [  20   68]]\n",
      "\n",
      " [[8078   30]\n",
      "  [  28   36]]\n",
      "\n",
      " [[8097    9]\n",
      "  [  23   43]]\n",
      "\n",
      " [[8081   12]\n",
      "  [  47   32]]\n",
      "\n",
      " [[8088   18]\n",
      "  [   7   59]]\n",
      "\n",
      " [[8095   15]\n",
      "  [  30   32]]\n",
      "\n",
      " [[8097   11]\n",
      "  [   8   56]]\n",
      "\n",
      " [[8104   10]\n",
      "  [  12   46]]\n",
      "\n",
      " [[8094   15]\n",
      "  [  17   46]]\n",
      "\n",
      " [[8083   26]\n",
      "  [  25   38]]\n",
      "\n",
      " [[8087   17]\n",
      "  [  32   36]]]\n",
      "Classification Report : \n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                 affenpinscher       0.83      0.83      0.83        63\n",
      "                  afghan_hound       0.95      0.85      0.90        94\n",
      "           african_hunting_dog       0.95      0.93      0.94        60\n",
      "                      airedale       0.79      0.80      0.79        84\n",
      "american_staffordshire_terrier       0.53      0.75      0.62        76\n",
      "                   appenzeller       0.67      0.65      0.66        65\n",
      "            australian_terrier       0.84      0.54      0.66        85\n",
      "                       basenji       0.79      0.77      0.78        79\n",
      "                        basset       0.66      0.73      0.70        67\n",
      "                        beagle       0.65      0.66      0.65        77\n",
      "            bedlington_terrier       0.91      0.94      0.93        66\n",
      "          bernese_mountain_dog       0.86      0.94      0.90        80\n",
      "              blenheim_spaniel       0.87      0.95      0.91        79\n",
      "                    bloodhound       0.78      0.77      0.78        75\n",
      "                      bluetick       0.86      0.90      0.88        69\n",
      "                 border_collie       0.78      0.34      0.47        62\n",
      "                border_terrier       0.93      0.81      0.86        78\n",
      "                        borzoi       0.88      0.62      0.73        61\n",
      "                   boston_bull       0.85      0.81      0.83        70\n",
      "          bouvier_des_flandres       0.53      0.85      0.65        55\n",
      "                         boxer       0.85      0.76      0.80        58\n",
      "             brabancon_griffon       0.74      0.94      0.83        54\n",
      "                        briard       0.82      0.58      0.68        72\n",
      "              brittany_spaniel       0.85      0.61      0.71        64\n",
      "                  bull_mastiff       0.78      0.83      0.80        64\n",
      "                         cairn       0.88      0.60      0.72        81\n",
      "                      cardigan       0.46      0.76      0.57        54\n",
      "      chesapeake_bay_retriever       0.74      0.87      0.80        62\n",
      "                     chihuahua       0.74      0.66      0.70        56\n",
      "                          chow       0.89      0.97      0.93        76\n",
      "                       clumber       0.80      0.92      0.86        49\n",
      "              coated_retriever       0.79      0.68      0.73        66\n",
      "        coated_wheaten_terrier       0.60      0.79      0.68        63\n",
      "                cocker_spaniel       0.77      0.67      0.72        72\n",
      "                        collie       0.43      0.73      0.54        59\n",
      "                dandie_dinmont       0.87      0.72      0.79        76\n",
      "                         dhole       0.79      0.92      0.85        60\n",
      "                         dingo       0.93      0.68      0.78        74\n",
      "                      doberman       0.71      0.47      0.57        57\n",
      "              english_foxhound       0.61      0.72      0.66        64\n",
      "                english_setter       0.66      0.84      0.74        77\n",
      "              english_springer       0.70      0.80      0.75        59\n",
      "                   entlebucher       0.73      0.76      0.74        74\n",
      "                    eskimo_dog       0.49      0.44      0.47        70\n",
      "                french_bulldog       0.80      0.80      0.80        59\n",
      "               german_shepherd       0.80      0.83      0.82        59\n",
      "               giant_schnauzer       0.62      0.69      0.65        70\n",
      "              golden_retriever       0.88      0.81      0.85        54\n",
      "                 gordon_setter       0.87      0.90      0.89        69\n",
      "                    great_dane       0.69      0.59      0.64        64\n",
      "                great_pyrenees       0.79      0.79      0.79        84\n",
      "    greater_swiss_mountain_dog       0.83      0.69      0.75        62\n",
      "                   groenendael       0.95      0.90      0.92        59\n",
      "            haired_fox_terrier       0.76      0.58      0.66        60\n",
      "                haired_pointer       0.92      0.70      0.79        66\n",
      "                  ibizan_hound       0.78      0.83      0.81        77\n",
      "                  irish_setter       0.94      0.87      0.90        67\n",
      "                 irish_terrier       0.81      0.64      0.72        59\n",
      "           irish_water_spaniel       0.93      0.83      0.88        65\n",
      "               irish_wolfhound       0.80      0.50      0.62       104\n",
      "             italian_greyhound       0.75      0.69      0.72        59\n",
      "              japanese_spaniel       0.98      0.65      0.79        81\n",
      "                      keeshond       1.00      0.94      0.97        69\n",
      "                        kelpie       0.47      0.77      0.58        57\n",
      "            kerry_blue_terrier       0.91      0.85      0.88        72\n",
      "                      komondor       0.98      0.93      0.95        67\n",
      "                        kuvasz       0.73      0.87      0.80        54\n",
      "            labrador_retriever       0.62      0.70      0.66        63\n",
      "              lakeland_terrier       0.62      0.75      0.68        72\n",
      "                      leonberg       0.90      0.93      0.92        87\n",
      "                         lhasa       0.40      0.59      0.48        66\n",
      "                      malamute       0.74      0.69      0.71        74\n",
      "                      malinois       0.90      0.87      0.88        52\n",
      "                   maltese_dog       0.85      0.78      0.81       106\n",
      "              mexican_hairless       0.91      0.86      0.89        73\n",
      "            miniature_pinscher       0.66      0.81      0.72        73\n",
      "              miniature_poodle       0.43      0.27      0.33        56\n",
      "           miniature_schnauzer       0.63      0.64      0.63        61\n",
      "                  newfoundland       0.59      0.78      0.67        74\n",
      "               norfolk_terrier       0.62      0.56      0.59        71\n",
      "            norwegian_elkhound       0.94      0.96      0.95        81\n",
      "               norwich_terrier       0.61      0.77      0.68        74\n",
      "          old_english_sheepdog       0.89      0.81      0.85        73\n",
      "                    otterhound       0.78      0.75      0.76        60\n",
      "                      papillon       0.79      0.99      0.88        70\n",
      "                      pekinese       0.58      0.83      0.68        54\n",
      "                      pembroke       0.83      0.49      0.62        79\n",
      "                    pomeranian       0.86      0.96      0.91        82\n",
      "                           pug       0.91      0.86      0.89        73\n",
      "                       redbone       0.70      0.75      0.73        57\n",
      "           rhodesian_ridgeback       0.68      0.60      0.64        68\n",
      "                    rottweiler       0.96      0.79      0.86        56\n",
      "                 saint_bernard       0.93      0.92      0.93        62\n",
      "                        saluki       0.87      0.80      0.84        86\n",
      "                       samoyed       0.82      0.90      0.86        82\n",
      "                    schipperke       0.83      0.89      0.86        55\n",
      "                scotch_terrier       0.89      0.74      0.81        76\n",
      "            scottish_deerhound       0.62      0.87      0.72        94\n",
      "              sealyham_terrier       0.90      0.88      0.89        80\n",
      "             shetland_sheepdog       0.74      0.53      0.61        59\n",
      "                siberian_husky       0.54      0.49      0.52        83\n",
      "                 silky_terrier       0.55      0.82      0.66        80\n",
      "     staffordshire_bullterrier       0.73      0.54      0.62        69\n",
      "               standard_poodle       0.56      0.81      0.66        63\n",
      "            standard_schnauzer       0.46      0.54      0.50        57\n",
      "                sussex_spaniel       0.96      0.87      0.91        61\n",
      "                 tan_coonhound       0.82      0.81      0.82        63\n",
      "               tibetan_mastiff       0.79      0.71      0.75        63\n",
      "               tibetan_terrier       0.60      0.77      0.67        88\n",
      "                    toy_poodle       0.55      0.56      0.55        64\n",
      "                   toy_terrier       0.83      0.65      0.73        66\n",
      "                           tzu       0.73      0.41      0.52        79\n",
      "                        vizsla       0.77      0.89      0.83        66\n",
      "                  walker_hound       0.68      0.52      0.59        62\n",
      "                    weimaraner       0.84      0.88      0.85        64\n",
      "        welsh_springer_spaniel       0.82      0.79      0.81        58\n",
      "   west_highland_white_terrier       0.75      0.73      0.74        63\n",
      "                       whippet       0.59      0.60      0.60        63\n",
      "             yorkshire_terrier       0.68      0.53      0.60        68\n",
      "\n",
      "                      accuracy                           0.75      8172\n",
      "                     macro avg       0.76      0.75      0.75      8172\n",
      "                  weighted avg       0.77      0.75      0.75      8172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert continuous predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test back to class labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Inverse transform the predicted and ground truth class labels to original breed names\n",
    "y_pred_breed = label_encoder.inverse_transform(y_pred_classes)\n",
    "y_test_breed = label_encoder.inverse_transform(y_test_classes)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "#print(\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
    "#print(\"Mean Square Error : \", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_test_breed, y_pred_breed))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test_breed, y_pred_breed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78860532-2cbd-4112-b51c-f0de5f5c1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 0s 680us/step\n",
      "256/256 [==============================] - 0s 576us/step\n",
      "256/256 [==============================] - 0s 576us/step\n",
      "256/256 [==============================] - 0s 620us/step\n",
      "256/256 [==============================] - 0s 578us/step\n",
      "256/256 [==============================] - 0s 569us/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_accuracy, best_params\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Usage example:\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m best_accuracy, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mperform_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest accuracy: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m best_accuracy)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mperform_grid_search\u001b[1;34m(x_train, y_train, x_test, y_test, param_grid)\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearn_rate), loss\u001b[38;5;241m=\u001b[39mLOSS_TYPE, metrics\u001b[38;5;241m=\u001b[39mMETRICS)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def perform_grid_search(x_train, y_train, x_test, y_test, param_grid):\n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "\n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for batch_size, epoch, first_layer, second_layer, learn_rate in itertools.product(param_grid['batch_size'], param_grid['epochs'], param_grid['first_layer'], param_grid['second_layer'], param_grid['learn_rate']):\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(first_layer, input_shape=(100,), activation=ACTIVATION_1))  # Assuming 100 features\n",
    "        model.add(Dense(second_layer, activation=ACTIVATION_2))\n",
    "        model.add(Dense(num_classes, activation=ACTIVATION_OUT))  # num_classes is the number of unique breed labels\n",
    "        model.compile(optimizer=Adam(learning_rate=learn_rate), loss=LOSS_TYPE, metrics=METRICS)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(x_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "        \n",
    "        # Check if current combination is better than the previous best\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {\n",
    "                'batch_size': batch_size,\n",
    "                'epochs': epoch,\n",
    "                'first_layer': first_layer,\n",
    "                'second_layer': second_layer,\n",
    "                'learn_rate': learn_rate\n",
    "            }\n",
    "\n",
    "    return best_accuracy, best_params\n",
    "\n",
    "# Usage example:\n",
    "best_accuracy, best_params = perform_grid_search(x_train, y_train, x_test, y_test, param_grid)\n",
    "print(\"Best accuracy: %f\" % best_accuracy)\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c3baa-a384-4601-9d6f-51b3fd5e0a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
