{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c480d74a-d567-46ac-812c-a790df98caa7",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7599a31-d302-46c6-a558-35b7d3a2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd374a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200cbb76-e40c-4f79-aef7-404b7e0777f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('features.csv')\n",
    "\n",
    "# x = df['Features']\n",
    "# y = df['Breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84336ead-25d3-401b-9e0e-311c35f29391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "    \n",
    "LEARN_RATE = 0.01\n",
    "FIRST_LAYER = 128 \n",
    "ACTIVATION_1 = 'relu'\n",
    "SECOND_LAYER = 64\n",
    "ACTIVATION_2 = 'softmax'\n",
    "ACTIVATION_OUT = 'softmax'\n",
    "LOSS_TYPE = 'sparse_categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "EPOCHS = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c12fe28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 90</th>\n",
       "      <th>Feature 91</th>\n",
       "      <th>Feature 92</th>\n",
       "      <th>Feature 93</th>\n",
       "      <th>Feature 94</th>\n",
       "      <th>Feature 95</th>\n",
       "      <th>Feature 96</th>\n",
       "      <th>Feature 97</th>\n",
       "      <th>Feature 98</th>\n",
       "      <th>Feature 99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>-5.279870</td>\n",
       "      <td>-2.208426</td>\n",
       "      <td>5.211814</td>\n",
       "      <td>-8.099501</td>\n",
       "      <td>-13.185220</td>\n",
       "      <td>-0.753768</td>\n",
       "      <td>-3.015471</td>\n",
       "      <td>0.825370</td>\n",
       "      <td>-4.269372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465695</td>\n",
       "      <td>-0.674558</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>-1.240681</td>\n",
       "      <td>-1.069499</td>\n",
       "      <td>-0.714136</td>\n",
       "      <td>1.011624</td>\n",
       "      <td>-0.225715</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>1.140998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>0.524020</td>\n",
       "      <td>-4.321692</td>\n",
       "      <td>-5.808849</td>\n",
       "      <td>-0.097443</td>\n",
       "      <td>-13.157566</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>-4.521323</td>\n",
       "      <td>-1.382092</td>\n",
       "      <td>-1.304059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410429</td>\n",
       "      <td>0.396908</td>\n",
       "      <td>0.344853</td>\n",
       "      <td>0.243527</td>\n",
       "      <td>-0.416206</td>\n",
       "      <td>0.310021</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>-0.221647</td>\n",
       "      <td>-0.306602</td>\n",
       "      <td>-0.855617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>4.484349</td>\n",
       "      <td>-11.409184</td>\n",
       "      <td>-2.061785</td>\n",
       "      <td>-8.795961</td>\n",
       "      <td>-10.736951</td>\n",
       "      <td>-0.650287</td>\n",
       "      <td>0.697348</td>\n",
       "      <td>8.464226</td>\n",
       "      <td>-2.961214</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.486026</td>\n",
       "      <td>0.636264</td>\n",
       "      <td>-0.315544</td>\n",
       "      <td>1.400241</td>\n",
       "      <td>-0.116869</td>\n",
       "      <td>-0.253275</td>\n",
       "      <td>0.918089</td>\n",
       "      <td>-0.645903</td>\n",
       "      <td>0.545067</td>\n",
       "      <td>-1.274210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>8.630311</td>\n",
       "      <td>-9.028896</td>\n",
       "      <td>-4.177602</td>\n",
       "      <td>-3.575223</td>\n",
       "      <td>-7.698362</td>\n",
       "      <td>-5.857273</td>\n",
       "      <td>-3.473359</td>\n",
       "      <td>6.915802</td>\n",
       "      <td>1.972978</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.718268</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.152345</td>\n",
       "      <td>0.562226</td>\n",
       "      <td>0.279578</td>\n",
       "      <td>-0.277104</td>\n",
       "      <td>-0.956852</td>\n",
       "      <td>-0.531012</td>\n",
       "      <td>0.249064</td>\n",
       "      <td>-1.877944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brittany_spaniel</td>\n",
       "      <td>-6.459163</td>\n",
       "      <td>-5.178344</td>\n",
       "      <td>3.182314</td>\n",
       "      <td>-6.884826</td>\n",
       "      <td>-2.663270</td>\n",
       "      <td>-0.779802</td>\n",
       "      <td>-0.788943</td>\n",
       "      <td>4.521932</td>\n",
       "      <td>-3.636744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.964177</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>-0.274313</td>\n",
       "      <td>-0.534803</td>\n",
       "      <td>0.797063</td>\n",
       "      <td>-0.156896</td>\n",
       "      <td>1.027882</td>\n",
       "      <td>1.130965</td>\n",
       "      <td>0.696718</td>\n",
       "      <td>0.098893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20423</th>\n",
       "      <td>basenji</td>\n",
       "      <td>9.544751</td>\n",
       "      <td>-11.946300</td>\n",
       "      <td>6.532518</td>\n",
       "      <td>6.032665</td>\n",
       "      <td>-0.054745</td>\n",
       "      <td>-2.835599</td>\n",
       "      <td>8.757513</td>\n",
       "      <td>2.183208</td>\n",
       "      <td>-3.308503</td>\n",
       "      <td>...</td>\n",
       "      <td>2.823255</td>\n",
       "      <td>1.785358</td>\n",
       "      <td>-0.389777</td>\n",
       "      <td>2.354301</td>\n",
       "      <td>-0.200981</td>\n",
       "      <td>1.370857</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.747879</td>\n",
       "      <td>-1.344105</td>\n",
       "      <td>-1.186251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20424</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-14.772338</td>\n",
       "      <td>-8.129835</td>\n",
       "      <td>6.266210</td>\n",
       "      <td>9.255338</td>\n",
       "      <td>-0.755042</td>\n",
       "      <td>-10.281703</td>\n",
       "      <td>-4.626710</td>\n",
       "      <td>3.558872</td>\n",
       "      <td>-6.597734</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.323281</td>\n",
       "      <td>-0.496995</td>\n",
       "      <td>-1.813071</td>\n",
       "      <td>0.129572</td>\n",
       "      <td>-0.680327</td>\n",
       "      <td>0.759279</td>\n",
       "      <td>-0.898638</td>\n",
       "      <td>0.825506</td>\n",
       "      <td>-1.794241</td>\n",
       "      <td>0.535946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20425</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-0.651727</td>\n",
       "      <td>-14.567093</td>\n",
       "      <td>19.406995</td>\n",
       "      <td>0.646407</td>\n",
       "      <td>10.396984</td>\n",
       "      <td>-6.700563</td>\n",
       "      <td>-4.514317</td>\n",
       "      <td>13.566748</td>\n",
       "      <td>-2.614418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.489337</td>\n",
       "      <td>2.132769</td>\n",
       "      <td>0.234950</td>\n",
       "      <td>-1.367633</td>\n",
       "      <td>-1.451568</td>\n",
       "      <td>0.228860</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>0.696946</td>\n",
       "      <td>-0.543697</td>\n",
       "      <td>-1.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20426</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-1.703676</td>\n",
       "      <td>-2.682114</td>\n",
       "      <td>14.418438</td>\n",
       "      <td>7.169161</td>\n",
       "      <td>6.828974</td>\n",
       "      <td>-6.077620</td>\n",
       "      <td>-2.837851</td>\n",
       "      <td>11.472995</td>\n",
       "      <td>-8.041656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.308288</td>\n",
       "      <td>-0.401849</td>\n",
       "      <td>1.429980</td>\n",
       "      <td>-0.723179</td>\n",
       "      <td>-2.111574</td>\n",
       "      <td>-1.035175</td>\n",
       "      <td>-0.324995</td>\n",
       "      <td>0.698054</td>\n",
       "      <td>0.101706</td>\n",
       "      <td>0.878638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20427</th>\n",
       "      <td>basenji</td>\n",
       "      <td>-1.798135</td>\n",
       "      <td>-4.808407</td>\n",
       "      <td>4.453213</td>\n",
       "      <td>6.871646</td>\n",
       "      <td>2.610319</td>\n",
       "      <td>-11.454654</td>\n",
       "      <td>3.632534</td>\n",
       "      <td>-3.067008</td>\n",
       "      <td>-3.319274</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.445148</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.543326</td>\n",
       "      <td>-0.379736</td>\n",
       "      <td>-1.181225</td>\n",
       "      <td>1.674236</td>\n",
       "      <td>0.643497</td>\n",
       "      <td>1.456580</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>1.196227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20428 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Breed  Feature 0  Feature 1  Feature 2  Feature 3  \\\n",
       "0      brittany_spaniel  -5.279870  -2.208426   5.211814  -8.099501   \n",
       "1      brittany_spaniel   0.524020  -4.321692  -5.808849  -0.097443   \n",
       "2      brittany_spaniel   4.484349 -11.409184  -2.061785  -8.795961   \n",
       "3      brittany_spaniel   8.630311  -9.028896  -4.177602  -3.575223   \n",
       "4      brittany_spaniel  -6.459163  -5.178344   3.182314  -6.884826   \n",
       "...                 ...        ...        ...        ...        ...   \n",
       "20423           basenji   9.544751 -11.946300   6.532518   6.032665   \n",
       "20424           basenji -14.772338  -8.129835   6.266210   9.255338   \n",
       "20425           basenji  -0.651727 -14.567093  19.406995   0.646407   \n",
       "20426           basenji  -1.703676  -2.682114  14.418438   7.169161   \n",
       "20427           basenji  -1.798135  -4.808407   4.453213   6.871646   \n",
       "\n",
       "       Feature 4  Feature 5  Feature 6  Feature 7  Feature 8  ...  Feature 90  \\\n",
       "0     -13.185220  -0.753768  -3.015471   0.825370  -4.269372  ...   -0.465695   \n",
       "1     -13.157566   0.439865  -4.521323  -1.382092  -1.304059  ...   -0.410429   \n",
       "2     -10.736951  -0.650287   0.697348   8.464226  -2.961214  ...   -1.486026   \n",
       "3      -7.698362  -5.857273  -3.473359   6.915802   1.972978  ...   -1.718268   \n",
       "4      -2.663270  -0.779802  -0.788943   4.521932  -3.636744  ...   -0.964177   \n",
       "...          ...        ...        ...        ...        ...  ...         ...   \n",
       "20423  -0.054745  -2.835599   8.757513   2.183208  -3.308503  ...    2.823255   \n",
       "20424  -0.755042 -10.281703  -4.626710   3.558872  -6.597734  ...   -1.323281   \n",
       "20425  10.396984  -6.700563  -4.514317  13.566748  -2.614418  ...   -0.489337   \n",
       "20426   6.828974  -6.077620  -2.837851  11.472995  -8.041656  ...    1.308288   \n",
       "20427   2.610319 -11.454654   3.632534  -3.067008  -3.319274  ...   -1.445148   \n",
       "\n",
       "       Feature 91  Feature 92  Feature 93  Feature 94  Feature 95  Feature 96  \\\n",
       "0       -0.674558    0.123558   -1.240681   -1.069499   -0.714136    1.011624   \n",
       "1        0.396908    0.344853    0.243527   -0.416206    0.310021    0.025371   \n",
       "2        0.636264   -0.315544    1.400241   -0.116869   -0.253275    0.918089   \n",
       "3        0.056995    0.152345    0.562226    0.279578   -0.277104   -0.956852   \n",
       "4        0.368517   -0.274313   -0.534803    0.797063   -0.156896    1.027882   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "20423    1.785358   -0.389777    2.354301   -0.200981    1.370857    0.069524   \n",
       "20424   -0.496995   -1.813071    0.129572   -0.680327    0.759279   -0.898638   \n",
       "20425    2.132769    0.234950   -1.367633   -1.451568    0.228860   -0.094061   \n",
       "20426   -0.401849    1.429980   -0.723179   -2.111574   -1.035175   -0.324995   \n",
       "20427    0.125831    0.543326   -0.379736   -1.181225    1.674236    0.643497   \n",
       "\n",
       "       Feature 97  Feature 98  Feature 99  \n",
       "0       -0.225715   -0.220330    1.140998  \n",
       "1       -0.221647   -0.306602   -0.855617  \n",
       "2       -0.645903    0.545067   -1.274210  \n",
       "3       -0.531012    0.249064   -1.877944  \n",
       "4        1.130965    0.696718    0.098893  \n",
       "...           ...         ...         ...  \n",
       "20423    0.747879   -1.344105   -1.186251  \n",
       "20424    0.825506   -1.794241    0.535946  \n",
       "20425    0.696946   -0.543697   -1.004654  \n",
       "20426    0.698054    0.101706    0.878638  \n",
       "20427    1.456580   -0.038680    1.196227  \n",
       "\n",
       "[20428 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f989db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breed\n",
       "maltese_dog             40\n",
       "afghan_hound            38\n",
       "scottish_deerhound      38\n",
       "pomeranian              37\n",
       "bernese_mountain_dog    37\n",
       "Name: count, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 90</th>\n",
       "      <th>Feature 91</th>\n",
       "      <th>Feature 92</th>\n",
       "      <th>Feature 93</th>\n",
       "      <th>Feature 94</th>\n",
       "      <th>Feature 95</th>\n",
       "      <th>Feature 96</th>\n",
       "      <th>Feature 97</th>\n",
       "      <th>Feature 98</th>\n",
       "      <th>Feature 99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-17.769237</td>\n",
       "      <td>3.806056</td>\n",
       "      <td>-7.947192</td>\n",
       "      <td>-7.745222</td>\n",
       "      <td>-3.001273</td>\n",
       "      <td>-5.717185</td>\n",
       "      <td>-0.134337</td>\n",
       "      <td>-5.785187</td>\n",
       "      <td>1.986444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468322</td>\n",
       "      <td>-0.581834</td>\n",
       "      <td>-0.269858</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>0.042755</td>\n",
       "      <td>-1.167644</td>\n",
       "      <td>0.624601</td>\n",
       "      <td>0.483681</td>\n",
       "      <td>-0.110365</td>\n",
       "      <td>0.197553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-4.460376</td>\n",
       "      <td>5.383997</td>\n",
       "      <td>-12.785639</td>\n",
       "      <td>-3.001283</td>\n",
       "      <td>-1.223234</td>\n",
       "      <td>-3.282389</td>\n",
       "      <td>-2.041132</td>\n",
       "      <td>-0.124060</td>\n",
       "      <td>-2.913089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283447</td>\n",
       "      <td>0.221348</td>\n",
       "      <td>0.291961</td>\n",
       "      <td>-0.169886</td>\n",
       "      <td>-0.994001</td>\n",
       "      <td>-0.574207</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.448076</td>\n",
       "      <td>0.644648</td>\n",
       "      <td>0.187503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-8.779060</td>\n",
       "      <td>6.070661</td>\n",
       "      <td>-5.718868</td>\n",
       "      <td>-8.548519</td>\n",
       "      <td>-4.457152</td>\n",
       "      <td>-2.430571</td>\n",
       "      <td>-0.080622</td>\n",
       "      <td>-5.815580</td>\n",
       "      <td>-1.548576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632971</td>\n",
       "      <td>0.216414</td>\n",
       "      <td>-0.712645</td>\n",
       "      <td>0.237740</td>\n",
       "      <td>-0.077775</td>\n",
       "      <td>0.759907</td>\n",
       "      <td>0.673151</td>\n",
       "      <td>-0.639458</td>\n",
       "      <td>1.022374</td>\n",
       "      <td>0.761278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-4.734003</td>\n",
       "      <td>8.879611</td>\n",
       "      <td>-8.251473</td>\n",
       "      <td>-6.424312</td>\n",
       "      <td>-5.072394</td>\n",
       "      <td>-2.460215</td>\n",
       "      <td>-1.800989</td>\n",
       "      <td>-6.557259</td>\n",
       "      <td>1.147739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152409</td>\n",
       "      <td>0.132250</td>\n",
       "      <td>-0.433237</td>\n",
       "      <td>0.266782</td>\n",
       "      <td>-0.545386</td>\n",
       "      <td>-0.188040</td>\n",
       "      <td>-0.155494</td>\n",
       "      <td>-0.821411</td>\n",
       "      <td>-0.033255</td>\n",
       "      <td>0.398598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>-15.576115</td>\n",
       "      <td>8.610791</td>\n",
       "      <td>-10.556212</td>\n",
       "      <td>-6.349051</td>\n",
       "      <td>-1.530232</td>\n",
       "      <td>-6.762910</td>\n",
       "      <td>-2.416079</td>\n",
       "      <td>-7.764591</td>\n",
       "      <td>2.224122</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.920712</td>\n",
       "      <td>-0.411785</td>\n",
       "      <td>0.256676</td>\n",
       "      <td>-0.075454</td>\n",
       "      <td>-0.889083</td>\n",
       "      <td>-1.006249</td>\n",
       "      <td>0.329453</td>\n",
       "      <td>-0.219117</td>\n",
       "      <td>0.703850</td>\n",
       "      <td>-0.064862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Breed  Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0  maltese_dog -17.769237   3.806056  -7.947192  -7.745222  -3.001273   \n",
       "1  maltese_dog  -4.460376   5.383997 -12.785639  -3.001283  -1.223234   \n",
       "2  maltese_dog  -8.779060   6.070661  -5.718868  -8.548519  -4.457152   \n",
       "3  maltese_dog  -4.734003   8.879611  -8.251473  -6.424312  -5.072394   \n",
       "4  maltese_dog -15.576115   8.610791 -10.556212  -6.349051  -1.530232   \n",
       "\n",
       "   Feature 5  Feature 6  Feature 7  Feature 8  ...  Feature 90  Feature 91  \\\n",
       "0  -5.717185  -0.134337  -5.785187   1.986444  ...   -0.468322   -0.581834   \n",
       "1  -3.282389  -2.041132  -0.124060  -2.913089  ...   -0.283447    0.221348   \n",
       "2  -2.430571  -0.080622  -5.815580  -1.548576  ...    0.632971    0.216414   \n",
       "3  -2.460215  -1.800989  -6.557259   1.147739  ...    0.152409    0.132250   \n",
       "4  -6.762910  -2.416079  -7.764591   2.224122  ...   -1.920712   -0.411785   \n",
       "\n",
       "   Feature 92  Feature 93  Feature 94  Feature 95  Feature 96  Feature 97  \\\n",
       "0   -0.269858   -0.008437    0.042755   -1.167644    0.624601    0.483681   \n",
       "1    0.291961   -0.169886   -0.994001   -0.574207    0.899105    0.448076   \n",
       "2   -0.712645    0.237740   -0.077775    0.759907    0.673151   -0.639458   \n",
       "3   -0.433237    0.266782   -0.545386   -0.188040   -0.155494   -0.821411   \n",
       "4    0.256676   -0.075454   -0.889083   -1.006249    0.329453   -0.219117   \n",
       "\n",
       "   Feature 98  Feature 99  \n",
       "0   -0.110365    0.197553  \n",
       "1    0.644648    0.187503  \n",
       "2    1.022374    0.761278  \n",
       "3   -0.033255    0.398598  \n",
       "4    0.703850   -0.064862  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the number of samples to take for each breed\n",
    "breed_counts = df['Breed'].value_counts()\n",
    "max_count = breed_counts.max()\n",
    "sample_sizes = np.maximum(20, 20 + (breed_counts / max_count * 20).astype(int))\n",
    "\n",
    "# Create an empty list to store sampled dataframes\n",
    "sampled_dfs = []\n",
    "\n",
    "# Iterate over each breed to sample data\n",
    "for breed, sample_size in sample_sizes.items():\n",
    "    # Get indices of rows corresponding to the current breed\n",
    "    breed_indices = df[df['Breed'] == breed].index\n",
    "    \n",
    "    # Randomly sample rows for the current breed\n",
    "    sampled_indices = np.random.choice(breed_indices, size=sample_size, replace=False)\n",
    "    \n",
    "    # Append sampled rows to the list\n",
    "    sampled_dfs.append(df.loc[sampled_indices])\n",
    "\n",
    "# Concatenate all sampled dataframes into one\n",
    "sampled_df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "display(sample_sizes.head())\n",
    "display(sampled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e9f19a-4a2a-496b-b444-21cc53a0b516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# Generate some dummy data for training\n",
    "\n",
    "x = sampled_df.drop(columns=['Breed'])\n",
    "\n",
    "y = sampled_df['Breed']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "num_classes = 120\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be0facdc-6b55-44b7-9e58-cd09912f0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the categorical target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the encoded labels to one-hot encoding\n",
    "y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b11822a6-d107-4ba2-b268-e31efe07dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Temp\\ipykernel_255736\\1389344705.py\", line 10, in <module>\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,120] and labels shape [3840]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3899]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mLEARN_RATE), loss\u001b[38;5;241m=\u001b[39mLOSS_TYPE, metrics\u001b[38;5;241m=\u001b[39mMETRICS)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Temp\\ipykernel_255736\\1389344705.py\", line 10, in <module>\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Kirin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,120] and labels shape [3840]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3899]"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(FIRST_LAYER, input_shape=(100,), activation=ACTIVATION_1)) # Assuming 100 features\n",
    "model.add(Dense(SECOND_LAYER, activation=ACTIVATION_2))\n",
    "model.add(Dense(num_classes, activation=ACTIVATION_OUT)) # num_classes is the number of unique breed labels\n",
    "model.compile(optimizer=Adam(learning_rate=LEARN_RATE), loss=LOSS_TYPE, metrics=METRICS)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1b997-4437-4ad5-ba4e-008b127f9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "#print(\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
    "#print(\"Mean Square Error : \", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78860532-2cbd-4112-b51c-f0de5f5c1539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
